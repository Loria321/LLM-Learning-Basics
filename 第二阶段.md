# 第二阶段：数据工程核心技术重点突破（第3-14周）详细学习计划
**核心目标**：精通大模型应用的四大核心数据技术（数据清洗、特征工程、向量数据库、数据集构建），达到企业初级数据工程师水平，形成可复用的工具脚本与标准化数据集
**学习节奏**：工作日每天2-2.5小时（晚7:00-9:30），周末每天4小时（上午9:00-13:00）
**核心产出**：4类数据工具脚本、3个标准化数据集、5份技术报告、1个RAG数据层原型

## 模块1：数据清洗技术（第3-6周，4周）—— 大模型数据质量的第一道防线
### 核心定位：数据清洗是大模型“垃圾进、垃圾出”的关键解决方案，本模块聚焦**文本+结构化数据**的清洗能力，适配大模型输入需求

| 周次 | 日期 | 细分任务 | 具体操作步骤 | 学习资源 | 预期成果 | 时间分配 |
|------|------|----------|--------------|----------|----------|----------|
| **第3周**<br>基础工具与流程 | 周一 | Pandas核心清洗函数学习 | 1. 掌握数据读取：`pd.read_csv/read_json/read_excel`；<br>2. 核心清洗操作：去重(`drop_duplicates`)、缺失值处理(`fillna/dropna`)、数据类型转换(`astype`)；<br>3. 完成3个基础练习：读取CSV→去重→缺失值填充→保存 | B站《Pandas数据清洗实战》P1-P3；<br>Pandas官方文档-清洗模块 | 练习代码3份；<br>函数用法笔记1页 | 2小时 |
| | 周二 | 异常值检测与处理 | 1. 学习异常值识别方法：描述统计(`describe`)、箱线图(`boxplot`)；<br>2. 处理策略：删除/替换/分箱；<br>3. 实操：处理Kaggle“学生成绩数据”中的异常分数 | 同上视频P4-P5；<br>Kaggle数据集：Student Performance | 异常值处理脚本；<br>处理前后数据对比表 | 2小时 |
| | 周三 | 通用清洗流程梳理 | 1. 总结标准化清洗流程：<br>数据加载→探索性分析→去重→缺失值→异常值→格式标准化→保存；<br>2. 编写流程思维导图，标注每个步骤的判断条件（如缺失值>30%则删除列） | 自制思维导图（XMind/手写） | 清洗流程思维导图；<br>判断条件清单 | 1.5小时 |
| | 周四 | 通用清洗脚本V1.0开发 | 1. 封装清洗流程为Python函数，支持参数配置（如缺失值填充策略）；<br>2. 脚本功能：输入任意CSV文件，输出清洗后的文件+清洗日志；<br>3. 测试：用“学生成绩数据”验证脚本 | VS Code编写代码，添加详细注释 | 通用清洗脚本V1.0（`.py`）；<br>测试日志1份 | 2.5小时 |
| | 周五 | 脚本优化与异常处理 | 1. 为脚本添加异常处理（文件不存在、格式错误）；<br>2. 增加命令行参数支持（`argparse`），可通过终端直接运行；<br>3. 测试不同异常场景（如传入Excel文件） | Python `argparse`官方文档；<br>异常处理教程 | 优化后脚本V1.1；<br>异常测试报告 | 2小时 |
| | 周六 | 实战：清洗Kaggle电影评论数据 | 1. 下载Kaggle“IMDB电影评论数据集”（5000条）；<br>2. 用V1.1脚本完成清洗：去重→删除空评论→统一文本编码；<br>3. 对比清洗前后数据量变化，计算清洗率 | Kaggle数据集：IMDB Dataset | 清洗后的电影评论数据集；<br>清洗率计算报告（清洗率=清洗后数量/原始数量） | 4小时 |
| | 周日 | 周复盘与问题整理 | 1. 总结本周核心知识点：Pandas清洗函数+通用流程；<br>2. 整理未解决问题（如复杂文本去噪）；<br>3. 上传脚本与数据集到GitHub | GitHub仓库更新 | 周复盘笔记；<br>GitHub提交记录 | 2小时 |
| **第4周**<br>文本数据专项清洗 | 周一 | 文本去噪技术学习 | 1. 掌握正则表达式(`re`)：去除HTML标签、特殊符号、多余空格；<br>2. 实操：用正则清洗电影评论中的`<br>`标签和表情符号；<br>3. 编写去噪函数，集成到清洗脚本 | Python `re`官方文档；<br>《正则表达式30分钟入门》 | 正则去噪函数；<br>去噪前后文本对比样例 | 2.5小时 |
| | 周二 | 中文文本处理（分词+去停用词） | 1. 安装NLTK/Spacy（中文模型）；<br>2. 学习分词：`nltk.word_tokenize`/`spacy.load("zh_core_web_sm")`；<br>3. 学习去停用词：加载中文停用词表，删除无意义词汇（的、了、吗） | NLTK中文停用词表；<br>Spacy中文模型安装教程 | 分词+去停用词函数；<br>处理后的文本样例 | 2小时 |
| | 周三 | 文本清洗脚本拓展 | 1. 为通用清洗脚本添加文本专项模块：正则去噪+分词+去停用词；<br>2. 新增参数：是否开启分词、是否去停用词；<br>3. 测试：清洗中文新闻文本 | 自制中文新闻测试文本（100条） | 文本专项清洗脚本V2.0；<br>中文文本清洗测试报告 | 2.5小时 |
| | 周四 | 实战：清洗杭电校园问答原始数据 | 1. 爬取杭电官网/贴吧的校园问答数据（1000条，杂乱格式）；<br>2. 用V2.0脚本清洗：去噪→分词→去停用词→筛选有效问答（问题+答案成对）；<br>3. 人工审核前100条，修正清洗错误 | 爬虫工具：BeautifulSoup（可选，或手动收集） | 清洗后的杭电校园问答数据集（800条有效）；<br>人工审核报告 | 2小时 |
| | 周五 | 文本质量评估 | 1. 学习文本质量指标：文本长度分布、有效词汇占比；<br>2. 编写评估函数，计算清洗后文本的平均长度、有效词汇占比；<br>3. 对比清洗前后的指标变化 | 知乎文章《大模型文本数据质量评估方法》 | 文本质量评估函数；<br>校园问答数据质量报告 | 2小时 |
| | 周六 | 脚本集成与文档编写 | 1. 整合文本清洗模块与基础清洗脚本，形成V2.1版本；<br>2. 编写脚本使用手册：参数说明、使用案例、输出格式；<br>3. 录制脚本运行演示视频（1分钟） | 录屏工具：OBS/剪映 | 集成版脚本V2.1；<br>使用手册+演示视频 | 4小时 |
| | 周日 | 周复盘与成果整理 | 1. 总结文本清洗核心技术：正则去噪+分词+质量评估；<br>2. 上传V2.1脚本与校园问答数据集到GitHub；<br>3. 规划下周结构化数据清洗重点 | GitHub仓库更新 | 周复盘笔记；<br>下周学习计划 | 2小时 |
| **第5周**<br>结构化数据清洗与格式转换 | 周一 | 多格式数据处理 | 1. 学习JSON/Excel数据清洗：`pd.read_json`/`pd.read_excel`；<br>2. 处理JSON嵌套数据：`json_normalize`展开嵌套字段；<br>3. 实操：清洗电商商品JSON数据（含嵌套的“规格”字段） | Pandas `json_normalize`官方文档；<br>电商JSON测试数据 | JSON数据清洗脚本；<br>展开后的结构化数据 | 2小时 |
| | 周二 | 数据格式标准化 | 1. 学习大模型常用数据格式：CSV（通用）、JSONL（微调专用）；<br>2. 编写格式转换函数：CSV→JSONL、Excel→CSV；<br>3. 转换要求：JSONL每行一条数据，字段为`{"question": "...", "answer": "..."}` | 大模型微调数据集格式规范（参考Hugging Face） | 格式转换函数；<br>不同格式的数据集样例 | 2.5小时 |
| | 周三 | 数据校验规则设计 | 1. 学习数据校验方法：字段类型校验、逻辑一致性校验；<br>2. 编写校验函数：检查问答数据是否存在“问题为空”“答案过短”（<10字）；<br>3. 实操：校验校园问答数据集，删除无效数据 | 自制校验规则清单 | 数据校验函数；<br>校园问答数据集校验报告 | 2小时 |
| | 周四 | 结构化数据清洗工具开发 | 1. 集成多格式处理+格式转换+数据校验，开发结构化数据清洗工具；<br>2. 工具功能：支持CSV/JSON/Excel输入→清洗→校验→输出JSONL；<br>3. 测试：处理电商商品数据，转换为大模型微调格式 | VS Code编写代码，添加注释 | 结构化数据清洗工具V1.0；<br>电商数据转换成果 | 2.5小时 |
| | 周五 | 复杂场景处理（重复字段/冗余数据） | 1. 学习处理重复字段：合并相同字段（如“商品名称”和“产品名”）；<br>2. 学习冗余数据删除：删除与大模型任务无关的字段（如电商数据中的“销量”）；<br>3. 优化工具，支持字段映射配置 | 自制复杂结构化数据（含重复字段） | 工具优化版V1.1；<br>复杂数据处理报告 | 2小时 |
| | 周六 | 实战：处理企业公开数据集 | 1. 下载“金融风控问答数据集”（Excel格式，含嵌套字段）；<br>2. 用V1.1工具完成全流程：清洗→校验→转换为JSONL；<br>3. 生成数据处理报告，记录每个步骤的数据变化 | 公开数据集平台：天池/ Kaggle | 金融风控JSONL数据集；<br>全流程处理报告 | 4小时 |
| | 周日 | 周复盘与工具优化 | 1. 总结结构化数据清洗核心：多格式支持+格式标准化+校验；<br>2. 修复工具已知Bug（如JSON嵌套过深）；<br>上传工具与金融数据集到GitHub | GitHub仓库更新 | 周复盘笔记；<br>工具Bug修复记录 | 2小时 |
| **第6周**<br>批量处理与自动化 | 周一 | 批量文件处理技术 | 1. 学习Python文件遍历：`os.walk`遍历指定文件夹下的所有数据文件；<br>2. 编写批量处理函数：自动识别文件格式（CSV/JSON/Excel）并调用对应清洗逻辑；<br>3. 测试：批量处理10个不同格式的数据集 | Python `os`官方文档 | 批量处理函数；<br>批量测试报告 | 2.5小时 |
| | 周二 | 多线程加速清洗 | 1. 学习Python多线程：`threading`模块，为批量处理添加多线程支持；<br>2. 对比单线程与多线程的处理速度（10个数据集）；<br>3. 优化线程数，避免资源占用过高 | Python `threading`官方文档；<br>多线程性能优化教程 | 多线程批量清洗脚本；<br>性能对比报告 | 2小时 |
| | 周三 | 自动化清洗流程搭建 | 1. 编写自动化脚本：定时任务（`schedule`库）+ 批量清洗 + 结果归档；<br>2. 配置：每天凌晨1点自动清洗指定文件夹的新数据，并归档到历史文件夹；<br>3. 测试定时任务功能 | Python `schedule`库文档 | 自动化清洗脚本；<br>定时任务测试记录 | 2.5小时 |
| | 周四 | 清洗质量自动评估 | 1. 集成前几周的质量评估函数，实现清洗后自动生成质量报告；<br>2. 报告内容：清洗率、有效数据占比、格式合规率；<br>3. 测试：批量清洗后自动生成10份质量报告 | 自制质量报告模板（Markdown） | 质量评估自动化模块；<br>10份自动生成的报告 | 2小时 |
| | 周五 | 全功能工具整合 | 1. 整合基础清洗+文本专项+结构化处理+批量自动化+质量评估，形成**大模型数据清洗工具箱V1.0**；<br>2. 编写工具箱使用指南，包含所有功能的参数说明和案例；<br>3. 打包工具箱为Python包（`setup.py`） | Python打包教程 | 大模型数据清洗工具箱V1.0；<br>使用指南+打包文件 | 2.5小时 |
| | 周六 | 实战：批量清洗10个领域数据集 | 1. 收集10个不同领域的数据集（教育、医疗、电商等）；<br>2. 用工具箱完成批量自动化清洗+质量评估；<br>3. 生成汇总报告：各领域数据清洗效果对比 | 公开数据集平台：天池/Kaggle | 10个清洗后的标准化数据集；<br>批量清洗汇总报告 | 4小时 |
| | 周日 | 模块验收与复盘 | 1. 模块验收标准：<br> - 能独立用工具箱清洗任意格式的文本/结构化数据；<br> - 能实现批量自动化处理并生成质量报告；<br>2. 上传工具箱到GitHub，发布V1.0版本；<br>3. 撰写模块总结笔记（数据清洗核心技术与最佳实践） | GitHub版本发布 | 模块验收报告；<br>总结笔记+GitHub仓库 | 2小时 |

## 模块2：特征工程与Embedding技术（第7-9周，3周）—— 让数据“被大模型读懂”
### 核心定位：特征工程是将原始数据转化为大模型可理解的向量特征的关键，本模块聚焦**文本特征提取**和**Embedding生成优化**，适配RAG与微调需求

| 周次 | 日期 | 细分任务 | 具体操作步骤 | 学习资源 | 预期成果 | 时间分配 |
|------|------|----------|--------------|----------|----------|----------|
| **第7周**<br>传统文本特征工程 | 周一 | 词袋模型与TF-IDF学习 | 1. 学习词袋模型（`CountVectorizer`）：统计词汇出现频率；<br>2. 学习TF-IDF（`TfidfVectorizer`）：衡量词汇重要性；<br>3. 实操：用两种方法提取校园问答数据的特征 | Scikit-learn `CountVectorizer`/`TfidfVectorizer`文档 | 特征提取脚本；<br>两种方法的特征矩阵 | 2小时 |
| | 周二 | 特征选择与降维 | 1. 学习特征选择：方差过滤、互信息法；<br>2. 学习降维技术：PCA（主成分分析）；<br>3. 实操：对TF-IDF特征矩阵进行降维，保留90%的信息 | Scikit-learn `PCA`官方文档；<br>特征选择教程 | 特征选择+降维脚本；<br>降维前后特征维度对比 | 2.5小时 |
| | 周三 | 传统特征与大模型适配性分析 | 1. 对比传统特征（TF-IDF）与大模型Embedding的区别：<br> - 语义表达能力（同义词识别）；<br> - 维度大小；<br>2. 测试：用两种特征分别训练分类模型，对比准确率 | Scikit-learn `LogisticRegression`分类器 | 特征对比报告；<br>分类模型准确率对比 | 2小时 |
| | 周四 | 传统特征工程脚本开发 | 1. 封装词袋/TF-IDF+特征选择+降维为函数；<br>2. 脚本功能：输入文本数据→输出低维特征矩阵；<br>3. 集成到数据清洗工具箱，作为特征提取模块 | VS Code编写代码 | 传统特征工程脚本；<br>工具箱特征模块 | 2.5小时 |
| | 周五 | 特征可视化分析 | 1. 学习用TSNE将高维特征降维到2D/3D；<br>2. 实操：可视化校园问答数据的TF-IDF特征，观察同类问题的聚类效果；<br>3. 分析聚类效果，优化特征提取参数 | Scikit-learn `TSNE`官方文档；<br>Matplotlib可视化教程 | 特征可视化脚本；<br>聚类效果分析报告 | 2小时 |
| | 周六 | 实战：传统特征在大模型中的应用 | 1. 将提取的TF-IDF特征作为Prompt的一部分输入大模型；<br>2. 测试：对比“纯文本输入”和“文本+特征输入”的模型输出准确率；<br>3. 总结传统特征的辅助作用 | 通义千问API调用脚本 | 特征辅助测试报告；<br>模型输出对比表 | 4小时 |
| | 周日 | 周复盘与疑问整理 | 1. 总结传统特征工程核心：词袋/TF-IDF+特征选择+可视化；<br>2. 整理疑问：传统特征与Embedding如何结合；<br>上传脚本到GitHub | GitHub仓库更新 | 周复盘笔记；<br>疑问清单 | 2小时 |
| **第8周**<br>大模型Embedding生成与优化 | 周一 | Embedding原理与选型 | 1. 学习Embedding核心原理：文本的向量表示，语义相近则向量距离近；<br>2. 对比主流Embedding模型：<br> - 开源：BERT-base、text2vec；<br> - 闭源：通义千问Embedding、OpenAI Embedding；<br>3. 选择text2vec（开源免费）和通义千问（效果好）作为学习对象 | Hugging Face Embedding模型库；<br>通义千问Embedding API文档 | Embedding原理笔记；<br>模型选型对比报告 | 2小时 |
| | 周二 | 开源Embedding模型使用 | 1. 安装`sentence-transformers`库，加载text2vec模型；<br>2. 编写脚本：输入文本→生成Embedding向量；<br>3. 实操：为校园问答数据生成开源Embedding向量 | `sentence-transformers`官方文档；<br>text2vec模型下载 | 开源Embedding生成脚本；<br>校园问答开源向量集 | 2.5小时 |
| | 周三 | 闭源Embedding API调用 | 1. 调用通义千问Embedding API，生成校园问答数据的闭源向量；<br>2. 对比开源与闭源向量的维度（text2vec：768维，通义千问：1024维）；<br>3. 计算两种向量的余弦相似度，验证语义一致性 | 通义千问Embedding API文档；<br>余弦相似度计算公式 | 闭源Embedding调用脚本；<br>向量对比报告 | 2小时 |
| | 周四 | Embedding优化技术 | 1. 学习Embedding优化方法：归一化（`sklearn.preprocessing.normalize`）、降维（PCA）；<br>2. 实操：对通义千问Embedding进行归一化+降维（768维）；<br>3. 对比优化前后的检索速度和准确率 | Scikit-learn归一化文档；<br>Embedding优化教程 | Embedding优化脚本；<br>优化前后性能对比 | 2.5小时 |
| | 周五 | Embedding生成工具开发 | 1. 封装开源/闭源Embedding生成+优化为函数；<br>2. 工具功能：支持模型选择、维度调整、归一化；<br>3. 集成到数据清洗工具箱，作为Embedding模块 | VS Code编写代码 | Embedding生成工具；<br>工具箱Embedding模块 | 2小时 |
| | 周六 | 实战：Embedding语义相似度验证 | 1. 选择5组同义词/近义词（如“课程”和“课表”）；<br>2. 生成每组词汇的Embedding向量，计算余弦相似度；<br>3. 测试：优化后的向量是否能更好地区分同义词和无关词 | 自制同义词测试集 | 语义相似度测试报告；<br>Embedding优化效果验证 | 4小时 |
| | 周日 | 周复盘与成果整理 | 1. 总结Embedding核心技术：开源/闭源模型使用+优化；<br>2. 上传Embedding工具与向量集到GitHub；<br>规划下周微调数据集特征工程 | GitHub仓库更新 | 周复盘笔记；<br>下周学习计划 | 2小时 |
| **第9周**<br>微调数据集特征工程 | 周一 | 大模型微调数据集格式规范 | 1. 学习微调数据集主流格式：JSONL（推荐）、CSV；<br>2. 格式要求：<br> - 监督微调（SFT）：`{"instruction": "...", "input": "...", "output": "..."}`；<br> - 对比学习：`{"prompt": "...", "chosen": "...", "rejected": "..."}`；<br>3. 编写格式校验函数 | Hugging Face微调数据集格式指南 | 格式规范笔记；<br>格式校验函数 | 2小时 |
| | 周二 | 微调数据特征对齐 | 1. 学习特征对齐方法：统一文本长度（截断/补齐）、标准化指令表述；<br>2. 实操：处理校园问答数据，统一指令为“请回答以下问题：{question}”；<br>3. 截断过长文本（超过512字），补齐过短文本（不足10字） | 大模型上下文长度规范（参考LLaMA-2） | 特征对齐脚本；<br>对齐后的微调数据集 | 2.5小时 |
| | 周三 | 标签处理与数据增强 | 1. 学习微调数据标签处理：确保输出答案的准确性、一致性；<br>2. 学习简单数据增强：同义词替换、句式变换；<br>3. 实操：对校园问答数据进行数据增强，扩充到1000条 | 中文同义词替换工具：`synonyms`库 | 标签处理+数据增强脚本；<br>扩充后的微调数据集（1000条） | 2小时 |
| | 周五 | 微调特征工程脚本开发 | 1. 集成格式转换+特征对齐+标签处理+数据增强，开发微调数据集特征工程脚本；<br>2. 脚本功能：输入原始问答数据→输出符合大模型微调要求的JSONL数据集；<br>3. 测试：处理金融风控数据，生成微调数据集 | VS Code编写代码 | 微调特征工程脚本；<br>金融风控微调数据集 | 2.5小时 |
| | 周四 | 微调数据集质量评估 | 1. 学习微调数据集质量指标：指令多样性、答案准确性、格式合规率；<br>2. 编写评估函数：自动计算上述指标；<br>3. 实操：评估校园问答微调数据集的质量 | 知乎文章《大模型微调数据集质量评估指南》 | 微调数据质量评估函数；<br>校园问答微调数据质量报告 | 2小时 |
| | 周六 | 实战：构建高质量微调数据集 | 1. 选择“智能科学专业知识”作为主题，收集500条原始问答；<br>2. 用脚本完成全流程特征工程：格式转换→对齐→增强→评估；<br>3. 人工审核前200条，修正低质量数据 | 自制智能科学专业问答集 | 高质量智能科学微调数据集（500条）；<br>全流程处理报告 | 4小时 |
| | 周日 | 模块验收与复盘 | 1. 模块验收标准：<br> - 能独立生成开源/闭源Embedding向量并优化；<br> - 能构建符合大模型微调要求的高质量数据集；<br>2. 上传微调脚本与数据集到GitHub；<br>3. 撰写模块总结笔记 | GitHub仓库更新 | 模块验收报告；<br>总结笔记 | 2小时 |

## 模块3：向量数据库应用（第10-12周，3周）—— 大模型RAG的核心存储引擎
### 核心定位：向量数据库是RAG架构中“检索”环节的核心，本模块聚焦**Chroma向量数据库**的使用与优化，实现高效的语义检索

| 周次 | 日期 | 细分任务 | 具体操作步骤 | 学习资源 | 预期成果 | 时间分配 |
|------|------|----------|----------|----------|----------|----------|
| **第10周**<br>向量数据库基础与选型 | 周一 | 向量数据库核心概念学习 | 1. 学习核心概念：向量存储、相似性检索、索引；<br>2. 对比主流向量数据库：<br> - Chroma（轻量、易上手，适合开发）；<br> - FAISS（开源、高性能）；<br> - Milvus（企业级）；<br>3. 选择Chroma作为主攻方向 | Chroma官方文档；<br>《向量数据库选型指南2025》 | 核心概念笔记；<br>选型对比报告 | 2小时 |
| | 周二 | Chroma安装与基础操作 | 1. 安装Chroma：`pip install chromadb`；<br>2. 学习基础操作：创建集合（`create_collection`）、添加向量（`add`）、查询（`query`）；<br>3. 实操：创建“杭电校园问答”集合，添加100条Embedding向量 | Chroma官方快速入门教程 | Chroma基础操作脚本；<br>校园问答向量集合 | 2.5小时 |
| | 周三 | 向量数据导入与管理 | 1. 编写批量导入脚本：读取Embedding向量集→批量添加到Chroma集合；<br>2. 学习集合管理：查看集合信息、修改元数据、删除向量；<br>3. 测试：导入800条校园问答向量，验证查询速度 | Chroma集合管理文档 | 批量导入脚本；<br>集合管理笔记 | 2小时 |
| | 周四 | 元数据过滤功能学习 | 1. 学习Chroma元数据过滤：添加元数据（如“领域：课程”），查询时按元数据筛选；<br>2. 实操：为校园问答向量添加元数据（课程/食堂/就业），实现“只查询课程相关问题”；<br>3. 编写元数据过滤查询脚本 | Chroma元数据过滤教程 | 元数据过滤脚本；<br>带元数据的向量集合 | 2.5小时 |
| | 周五 | Chroma与Embedding工具集成 | 1. 将Chroma操作集成到数据清洗工具箱，实现“Embedding生成→向量入库”一键完成；<br>2. 工具新增功能：向量批量导入、元数据自动添加；<br>3. 测试：用工具完成校园问答数据的Embedding生成+入库 | VS Code编写代码 | 工具箱向量数据库模块；<br>一键入库脚本 | 2小时 |
| | 周六 | 实战：对比Chroma与FAISS性能 | 1. 安装FAISS，导入相同的800条向量；<br>2. 对比两者的检索速度（查询100个问题）和召回率；<br>3. 总结：Chroma适合开发，FAISS适合高性能场景 | FAISS官方文档；<br>检索性能测试脚本 | 性能对比报告；<br>Chroma/FAISS使用场景总结 | 4小时 |
| | 周日 | 周复盘与问题整理 | 1. 总结Chroma核心操作：集合管理+向量导入+元数据过滤；<br>2. 整理疑问：如何提升检索准确率；<br>上传脚本到GitHub | GitHub仓库更新 | 周复盘笔记；<br>疑问清单 | 2小时 |
| **第11周**<br>向量检索优化 | 周一 | 检索算法原理学习 | 1. 学习主流检索算法：<br> - 暴力检索（Brute-force）：精准但慢；<br> - IVF（倒排索引）：平衡速度与精度；<br> - HNSW（分层导航小世界）：速度快；<br>2. 了解Chroma默认算法（HNSW）的参数含义 | Chroma检索算法文档；<br>《向量检索算法入门》 | 检索算法笔记；<br>参数含义清单 | 2小时 |
| | 周二 | Chroma索引参数优化 | 1. 学习Chroma索引参数：`hnsw:space`（距离度量）、`hnsw:m`（邻居数）、`hnsw:ef`（构建参数）；<br>2. 实操：调整参数（如`m=16→32`），测试检索召回率变化；<br>3. 找到最优参数组合（召回率≥90%） | Chroma索引优化教程 | 参数优化脚本；<br>参数-召回率对比表 | 2.5小时 |
| | 周三 | 检索结果重排序 | 1. 学习重排序技术：用CrossEncoder模型对检索结果重新排序；<br>2. 安装`sentence-transformers`的CrossEncoder模型；<br>3. 实操：先检索10条结果，再用重排序模型选出Top3 | CrossEncoder官方文档 | 重排序脚本；<br>重排序前后结果对比 | 2小时 |
| | 周四 | 检索优化工具开发 | 1. 封装索引参数优化+重排序为函数；<br>2. 工具功能：自动调参、检索结果重排序；<br>3. 集成到工具箱，提升检索准确率 | VS Code编写代码 | 检索优化工具；<br>工具箱检索优化模块 | 2.5小时 |
| | 周五 | 检索性能优化 | 1. 学习性能优化方法：批量查询、缓存热点数据；<br>2. 编写批量查询脚本，对比单条查询与批量查询的速度；<br>3. 实现缓存功能（`redis`），缓存高频查询的结果 | Redis Python客户端文档；<br>批量查询教程 | 性能优化脚本；<br>速度对比报告 | 2小时 |
| | 周六 | 实战：优化校园问答检索系统 | 1. 用优化后的工具搭建校园问答检索系统；<br>2. 测试：查询100个问题，验证召回率（≥90%）和响应时间（≤1秒/条）；<br>3. 生成检索系统性能报告 | 自制查询测试集（100个问题） | 优化后的检索系统；<br>性能测试报告 | 4小时 |
| | 周日 | 周复盘与成果整理 | 1. 总结检索优化核心技术：参数调优+重排序+性能优化；<br>2. 上传优化工具与检索系统到GitHub；<br>规划下周与LangChain集成 | GitHub仓库更新 | 周复盘笔记；<br>下周学习计划 | 2小时 |
| **第12周**<br>向量数据库与LangChain集成 | 周一 | LangChain核心概念学习 | 1. 学习LangChain核心组件：`DocumentLoader`、`TextSplitter`、`VectorStore`；<br>2. 重点学习`Chroma`与LangChain的集成方法；<br>3. 安装LangChain：`pip install langchain langchain-chroma` | LangChain官方文档；<br>LangChain-Chroma集成教程 | LangChain核心概念笔记；<br>环境搭建成功截图 | 2小时 |
| | 周二 | LangChain加载与分割文档 | 1. 学习`TextLoader`加载文本文件，`RecursiveCharacterTextSplitter`分割长文本；<br>2. 实操：加载杭电校园手册（长文本），分割为500字/段的小文档；<br>3. 为每个文档添加元数据（如“章节：招生就业”） | LangChain文档加载与分割教程 | 文档加载+分割脚本；<br>分割后的小文档集合 | 2.5小时 |
| | 周三 | LangChain+Chroma搭建RAG数据层 | 1. 编写脚本：分割后的文档→生成Embedding→存入Chroma；<br>2. 实现RAG核心流程：用户查询→检索相关文档→拼接为上下文；<br>3. 测试：查询“杭电智科专业就业率”，验证是否能检索到正确文档 | LangChain RAG快速入门教程 | RAG数据层脚本；<br>检索上下文样例 | 2小时 |
| | 周四 | RAG检索逻辑优化 | 1. 优化检索参数：调整`k`值（返回Top k条文档）、添加元数据过滤；<br>2. 测试不同`k`值（5/10/15）对检索效果的影响；<br>3. 找到最优`k`值（平衡相关性与冗余度） | LangChain检索参数文档 | 检索逻辑优化脚本；<br>`k`值效果对比报告 | 2.5小时 |
| | 周五 | RAG数据层与大模型联动 | 1. 集成通义千问API，实现“检索上下文→拼接Prompt→模型生成答案”；<br>2. 编写联动脚本：输入问题→检索→生成答案；<br>3. 对比“纯模型生成”和“RAG生成”的答案准确性 | 通义千问API调用脚本 | RAG-模型联动脚本；<br>答案准确性对比报告 | 2小时 |
| | 周六 | 实战：搭建智科专业RAG数据层原型 | 1. 以“智能科学专业知识库”为数据源，搭建完整RAG数据层；<br>2. 功能：支持专业问题检索、上下文生成、答案输出；<br>3. 录制原型演示视频（3分钟），展示核心流程 | 智能科学专业知识库文档 | RAG数据层原型；<br>演示视频+使用说明 | 4小时 |
| | 周日 | 模块验收与复盘 | 1. 模块验收标准：<br> - 能独立用LangChain+Chroma搭建RAG数据层；<br> - 能优化检索逻辑，实现召回率≥90%；<br>2. 上传RAG原型到GitHub；<br>3. 撰写模块总结笔记 | GitHub仓库更新 | 模块验收报告；<br>总结笔记 | 2小时 |

## 模块4：大模型数据集构建（第13-14周，2周）—— 从0到1打造专属高质量数据集
### 核心定位：数据集是大模型应用的“燃料”，本模块聚焦**自定义领域数据集**的设计、收集、清洗、评估全流程，适配智科专业场景

| 周次 | 日期 | 细分任务 | 具体操作步骤 | 学习资源 | 预期成果 | 时间分配 |
|------|------|----------|----------|----------|----------|----------|
| **第13周**<br>自定义数据集设计与收集 | 周一 | 数据集需求分析与方案设计 | 1. 确定数据集主题：**智能科学与技术专业知识库数据集**；<br>2. 明确应用场景：RAG问答、专业知识微调；<br>3. 设计数据集结构：<br> - 字段：`question`（问题）、`answer`（答案）、`domain`（领域）、`source`（来源）；<br> - 规模：500条以上；<br> - 领域覆盖：课程、就业、科研、竞赛 | 《大模型数据集设计指南》 | 数据集需求文档；<br>结构设计方案 | 2小时 |
| | 周二 | 数据来源渠道梳理 | 1. 梳理合法数据来源：<br> - 公开渠道：杭电官网、智科专业培养方案、行业论文摘要；<br> - 自制渠道：人工编写专业问答、学长学姐经验总结；<br>2. 制定数据收集规范：注明来源、确保无版权问题 | 杭电官网-智能科学与技术专业页面；<br>知网论文摘要 | 数据来源清单；<br>收集规范文档 | 2.5小时 |
| | 周三 | 数据收集工具开发 | 1. 编写爬虫脚本：爬取杭电官网的专业课程、就业信息；<br>2. 编写人工录入工具：Excel模板+格式校验；<br>3. 测试：爬取100条课程信息，人工录入100条就业问答 | BeautifulSoup爬虫教程；<br>Excel数据校验模板 | 爬虫脚本+人工录入模板；<br>初始数据集（200条） | 2小时 |
| | 周四 | 数据初步清洗与整合 | 1. 用之前开发的清洗工具箱对收集的数据进行初步清洗；<br>2. 整合爬虫数据与人工数据，统一字段格式；<br>3. 筛选有效数据，删除重复、无关内容 | 数据清洗工具箱V1.0 | 初步清洗后的数据集（300条）；<br>整合报告 | 2.5小时 |
| | 周五 | 数据集格式标准化 | 1. 将整合后的数据转换为两种格式：<br> - CSV（用于RAG）；<br> - JSONL（用于微调）；<br>2. 编写格式转换脚本，确保符合大模型要求；<br>3. 生成数据集说明文档，注明格式、字段、来源 | 大模型数据集格式规范 | 标准化数据集（CSV+JSONL）；<br>格式说明文档 | 2小时 |
| | 周六 | 数据扩充与增强 | 1. 用数据增强脚本对现有数据进行扩充（同义词替换、句式变换）；<br>2. 补充收集科研、竞赛领域的数据，使领域覆盖完整；<br>3. 最终扩充到500条以上 | 数据增强脚本（模块2） | 扩充后的数据集（550条）；<br>领域覆盖报告 | 4小时 |
| | 周日 | 周复盘与数据审核 | 1. 总结数据集收集核心：需求分析+多渠道收集+格式标准化；<br>2. 人工审核前100条数据，修正错误；<br>上传初步数据集到GitHub | GitHub仓库更新 | 周复盘笔记；<br>人工审核报告 | 2小时 |
| **第14周**<br>数据集质量评估与迭代 | 周一 | 数据集质量评估指标体系 | 1. 构建评估指标体系：<br> - 准确性：答案是否正确；<br> - 完整性：领域覆盖是否全面；<br> - 一致性：格式、术语是否统一；<br> - 多样性：问题类型是否多样；<br>2. 编写评估量表，每个指标评分（1-5分） | 《大模型数据集质量评估指标体系》 | 评估指标体系文档；<br>质量评估量表 | 2小时 |
| | 周二 | 自动评估与人工评估结合 | 1. 用之前开发的质量评估函数进行自动评估（格式合规率、有效数据占比）；<br>2. 组织3人小组进行人工评估（准确性、完整性），计算平均分；<br>3. 生成综合质量报告：自动评估得分+人工评估得分 | 质量评估函数（模块1/2） | 综合质量评估报告；<br>评分表 | 2.5小时 |
| | 周三 | 数据集迭代优化 | 1. 根据评估报告优化数据集：<br> - 修正错误答案；<br> - 补充缺失领域的数据；<br> - 统一术语（如“智科专业”统一为“智能科学与技术专业”）；<br>2. 优化后再次评估，确保综合得分≥4分 | 人工审核清单 | 优化后的数据集（500条高质量）；<br>迭代优化报告 | 2小时 |
| | 周四 | 数据集版本管理与共享 | 1. 学习数据集版本管理：用DVC（数据版本控制）管理不同版本；<br>2. 生成数据集最终版本（V1.0），标注版本号、更新日志；<br>3. 编写数据集共享文档，注明使用许可、引用方式 | DVC官方文档；<br>数据集共享规范 | 数据集V1.0（500条）；<br>版本日志+共享文档 | 2.5小时 |
| | 周五 | 数据集应用测试 | 1. 将数据集用于RAG数据层：测试专业问题的回答准确性；<br>2. 将数据集用于小样本微调：测试微调后模型的专业能力；<br>3. 生成应用测试报告，记录效果 | RAG数据层原型（模块3）；<br>LoRA微调脚本（后续学习） | 数据集应用测试报告；<br>效果对比表 | 2小时 |
| | 周六 | 第二阶段整体验收 | 1. 第二阶段验收标准：<br> - 掌握数据清洗、特征工程、向量数据库、数据集构建四大核心技术；<br> - 拥有4类工具脚本、3个标准化数据集、1个RAG原型；<br> - 能独立完成大模型数据工程全流程；<br>2. 整理第二阶段所有成果，形成数据工程技能包 | 自制验收 checklist | 第二阶段验收报告；<br>数据工程技能包（工具+数据集+报告） | 4小时 |
| | 周日 | 阶段复盘与大三规划 | 1. 撰写第二阶段学习总结（2000字），记录收获、难点、解决方案；<br>2. 规划大三学习方向：数据工程+大模型微调+项目实战；<br>3. 整理GitHub仓库，发布第二阶段成果 | GitHub仓库版本发布 | 阶段总结报告；<br>大三学习规划 | 2小时 |

## 第二阶段核心资源汇总
| 资源类型 | 具体内容 | 备注 |
|----------|----------|------|
| 工具库 | Pandas、NumPy、Chroma、LangChain、sentence-transformers | 全部开源免费 |
| 数据集 | Kaggle/天池公开数据集、杭电校园数据、智科专业知识库 | 自制数据集无版权问题 |
| 学习资料 | B站Pandas实战视频、Chroma官方文档、LangChain RAG教程 | 优先选择中文资料，降低理解难度 |
| 开发工具 | VS Code、GitHub、DrawIO、OBS | 代码托管+流程图+录屏 |

## 第二阶段注意事项
1. **聚焦数据工程**：不深入大模型底层原理，所有学习围绕“数据如何服务大模型”展开；
2. **成果沉淀优先**：每个脚本、数据集、报告都要上传GitHub，命名规范（如`data-cleaning-tool-v2.1.py`）；
3. **问题快速解决**：遇到技术问题优先查官方文档→CSDN搜索→问专业导师，避免卡壳超过1天；
4. **结合专业特色**：数据集和项目优先选择智科专业相关内容，提升简历针对性。