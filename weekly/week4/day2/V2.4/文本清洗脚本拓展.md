### 1. éœ€æ±‚ç¡®è®¤
ä½ éœ€è¦æ‹“å±•é€šç”¨æ–‡æœ¬æ¸…æ´—è„šæœ¬ï¼Œæ ¸å¿ƒæ˜¯**æ•´åˆæ­£åˆ™å»å™ªã€jiebaåˆ†è¯ã€å»åœç”¨è¯ä¸‰å¤§ä¸“é¡¹æ¨¡å—**ï¼Œå¹¶æ–°å¢ã€Œæ˜¯å¦å¼€å¯åˆ†è¯ã€ã€Œæ˜¯å¦å»åœç”¨è¯ã€çš„çµæ´»å‚æ•°æ§åˆ¶ï¼Œæœ€ç»ˆç”¨ä¸­æ–‡æ–°é—»æ–‡æœ¬å®ŒæˆåŠŸèƒ½æµ‹è¯•ã€‚æˆ‘ä¼šä¸ºä½ æä¾›ä¸€ä¸ª**æ¨¡å—åŒ–ã€å¯é…ç½®ã€æ˜“æ‰©å±•**çš„å®Œæ•´è„šæœ¬ï¼Œå…¼é¡¾å‚æ•°çµæ´»æ€§å’Œä¸­æ–‡æ–°é—»çš„é€‚é…æ€§ã€‚

### 2. å®Œæ•´æ‹“å±•ç‰ˆæ¸…æ´—è„šæœ¬ï¼ˆæ”¯æŒå‚æ•°å¼€å…³+ä¸­æ–‡æ–°é—»é€‚é…ï¼‰
è¯¥è„šæœ¬æ•´åˆäº†ã€Œæ­£åˆ™å»å™ªâ†’åˆ†è¯â†’å»åœç”¨è¯ã€å…¨æµç¨‹ï¼Œé€šè¿‡å‘½ä»¤è¡Œå‚æ•°æ§åˆ¶å„æ¨¡å—çš„å¯åœï¼Œå®Œå…¨é€‚é…ä¸­æ–‡æ–°é—»æ–‡æœ¬çš„æ¸…æ´—éœ€æ±‚ï¼š

```python
import pandas as pd
import numpy as np
import logging
from datetime import datetime
import os
import argparse
import traceback
import re
import unicodedata
import jieba

# ===================== å…¨å±€é…ç½®ï¼ˆå¯æŒ‰éœ€è°ƒæ•´ï¼‰ =====================
# åœç”¨è¯æ–‡ä»¶è·¯å¾„ï¼ˆè‹¥ä¸å­˜åœ¨åˆ™ä½¿ç”¨å†…ç½®é»˜è®¤åˆ—è¡¨ï¼‰
STOPWORDS_FILE = "cn_stopwords.txt"
# é»˜è®¤æ˜¯å¦å¼€å¯å„æ¨¡å—
DEFAULT_ENABLE_NOISE = True    # é»˜è®¤å¼€å¯æ­£åˆ™å»å™ª
DEFAULT_ENABLE_CUT = True      # é»˜è®¤å¼€å¯åˆ†è¯
DEFAULT_ENABLE_STOPWORDS = True# é»˜è®¤å¼€å¯å»åœç”¨è¯

# ===================== 1. å·¥å…·å‡½æ•°ï¼šæ­£åˆ™å»å™ªï¼ˆé€‚é…æ–°é—»æ–‡æœ¬ï¼‰ =====================
def clean_text_noise(text, lower_case=False):
    """
    æ­£åˆ™å»å™ªæ ¸å¿ƒå‡½æ•°ï¼ˆé€‚é…ä¸­æ–‡æ–°é—»ï¼‰ï¼šå»é™¤HTMLæ ‡ç­¾ã€emojiã€ç‰¹æ®Šç¬¦å·ã€å¤šä½™ç©ºæ ¼
    :param text: åŸå§‹æ–‡æœ¬
    :param lower_case: æ˜¯å¦è½¬ä¸ºå°å†™ï¼ˆä¸­æ–‡æ— æ„ä¹‰ï¼Œä»…å…¼å®¹ï¼‰
    :return: å»å™ªåçš„æ–‡æœ¬
    """
    # ç©ºå€¼å¤„ç†
    if pd.isna(text) or text is None or text.strip() == "":
        return ""
    
    # æ­¥éª¤1ï¼šç»Ÿä¸€ç¼–ç ï¼ˆå¤„ç†æ–°é—»ä¸­çš„ä¹±ç /éUTF-8å­—ç¬¦ï¼‰
    text = unicodedata.normalize('NFKD', text).encode('utf-8', 'ignore').decode('utf-8')
    
    # æ­¥éª¤2ï¼šå»é™¤HTMLæ ‡ç­¾ï¼ˆæ–°é—»å¸¸å«<p>ã€<br>ã€<a>ç­‰æ ‡ç­¾ï¼‰
    text = re.sub(r'<.*?>', '', text)
    
    # æ­¥éª¤3ï¼šå»é™¤emojiï¼ˆæ–°é—»è¯„è®ºåŒºå¯èƒ½å«è¡¨æƒ…ï¼‰
    emoji_pattern = re.compile("["
                               u"\U0001F600-\U0001F64F"  # è¡¨æƒ…ç¬¦å·
                               u"\U0001F300-\U0001F5FF"  # ç¬¦å·/å›¾æ ‡
                               u"\U0001F680-\U0001F6FF"  # äº¤é€š/åœ°å›¾ç¬¦å·
                               u"\U0001F1E0-\U0001F1FF"  # å›½æ——
                               u"\U00002500-\U00002BEF"  # æ‚é¡¹ç¬¦å·
                               u"\U00002702-\U000027B0"
                               u"\U000024C2-\U0001F251"
                               u"\U00010000-\U0010ffff"
                               "]+", flags=re.UNICODE)
    text = emoji_pattern.sub(r'', text)
    
    # æ­¥éª¤4ï¼šå»é™¤ç‰¹æ®Šç¬¦å·ï¼ˆä¿ç•™ä¸­æ–‡ã€å­—æ¯ã€æ•°å­—ã€åŸºç¡€æ ‡ç‚¹ï¼‰
    # æ–°é—»å¸¸å«çš„å™ªå£°ï¼šâ˜…ã€â– ã€ã€ã€‘ã€@ã€#ç­‰
    text = re.sub(r'[^\u4e00-\u9fa5a-zA-Z0-9\s.,!?ï¼Œã€‚ï¼ï¼Ÿã€ï¼šï¼›""''ï¼ˆï¼‰()]', ' ', text)
    
    # æ­¥éª¤5ï¼šåˆå¹¶å¤šä½™ç©ºæ ¼ï¼ˆæ¢è¡Œ/åˆ¶è¡¨ç¬¦/å¤šç©ºæ ¼â†’å•ä¸ªç©ºæ ¼ï¼‰
    text = re.sub(r'\s+', ' ', text).strip()
    
    # æ­¥éª¤6ï¼šå¯é€‰å°å†™ï¼ˆä¸­æ–‡æ— æ„ä¹‰ï¼Œä»…é€‚é…å¤šè¯­è¨€åœºæ™¯ï¼‰
    if lower_case:
        text = text.lower()
    
    return text

# ===================== 2. å·¥å…·å‡½æ•°ï¼šåœç”¨è¯åŠ è½½ =====================
def load_stopwords(file_path=STOPWORDS_FILE):
    """åŠ è½½ä¸­æ–‡åœç”¨è¯è¡¨ï¼ˆæœ¬åœ°æ–‡ä»¶ä¼˜å…ˆï¼Œå…œåº•å†…ç½®åˆ—è¡¨ï¼‰"""
    # å†…ç½®æ–°é—»åœºæ™¯åœç”¨è¯ï¼ˆè¡¥å……åŸºç¡€åœç”¨è¯+æ–°é—»ä¸“å±å™ªå£°è¯ï¼‰
    default_stopwords = {
        # åŸºç¡€åœç”¨è¯
        'çš„', 'äº†', 'å—', 'å•Š', 'è¿™', 'é‚£', 'åœ¨', 'æ˜¯', 'æˆ‘', 'ä½ ', 'ä»–', 
        'å¾ˆ', 'çœŸçš„', 'éƒ½', 'ä¹Ÿ', 'å°±', 'åˆ', 'è¿˜', 'å§', 'å‘¢', 'å“¦', 'å“ˆ',
        # æ ‡ç‚¹/ç¬¦å·
        'ï¼Œ', 'ã€‚', 'ï¼', 'ï¼Ÿ', 'ã€', 'ï¼š', 'ï¼›', 'â€œ', 'â€', 'ï¼ˆ', 'ï¼‰', ' ',
        # æ–°é—»ä¸“å±åœç”¨è¯
        'æœ¬æŠ¥', 'è®°è€…', 'æŠ¥é“', 'æ®æ‚‰', 'è¿‘æ—¥', 'ç›®å‰', 'ç›¸å…³', 'éƒ¨é—¨', 'è¡¨ç¤º',
        'è®¤ä¸º', 'æŒ‡å‡º', 'å¼ºè°ƒ', 'å‘å¸ƒ', 'å…¬å‘Š', 'é€šçŸ¥', 'ç§°', 'æ®äº†è§£', 'æ®ä»‹ç»'
    }
    try:
        with open(file_path, "r", encoding="utf-8") as f:
            stopwords = set([line.strip() for line in f.readlines() if line.strip()])
        # åˆå¹¶å†…ç½®åœç”¨è¯ï¼ˆé¿å…æœ¬åœ°æ–‡ä»¶ä¸å…¨ï¼‰
        stopwords = stopwords.union(default_stopwords)
        logging.info(f"âœ… æˆåŠŸåŠ è½½åœç”¨è¯è¡¨ï¼ˆæœ¬åœ°æ–‡ä»¶+å†…ç½®ï¼‰ï¼Œå…± {len(stopwords)} ä¸ªåœç”¨è¯")
    except FileNotFoundError:
        logging.warning(f"âš ï¸  æœªæ‰¾åˆ°åœç”¨è¯æ–‡ä»¶ {file_path}ï¼Œä½¿ç”¨å†…ç½®é»˜è®¤åˆ—è¡¨")
        stopwords = default_stopwords
    return stopwords

# ===================== 3. å·¥å…·å‡½æ•°ï¼šåˆ†è¯+å»åœç”¨è¯ï¼ˆå¸¦å¼€å…³ï¼‰ =====================
def cn_text_cut(text, enable_cut=True, enable_stopwords=True):
    """
    ä¸­æ–‡åˆ†è¯+å»åœç”¨è¯ï¼ˆæ”¯æŒå¼€å…³æ§åˆ¶ï¼‰
    :param text: å»å™ªåçš„æ–‡æœ¬
    :param enable_cut: æ˜¯å¦å¼€å¯åˆ†è¯ï¼ˆFalseåˆ™è¿”å›åŸæ–‡æœ¬ï¼‰
    :param enable_stopwords: æ˜¯å¦å»åœç”¨è¯ï¼ˆä»…å½“enable_cut=Trueæ—¶ç”Ÿæ•ˆï¼‰
    :return: å¤„ç†åçš„æ–‡æœ¬/åˆ†è¯åˆ—è¡¨ï¼ˆæ‹¼æ¥ä¸ºå­—ç¬¦ä¸²ä¾¿äºä¿å­˜ï¼‰
    """
    # ç©ºå€¼å¤„ç†
    if not text or text.strip() == "":
        return ""
    
    # ä¸å¼€å¯åˆ†è¯ï¼šç›´æ¥è¿”å›åŸæ–‡æœ¬
    if not enable_cut:
        return text
    
    # å¼€å¯åˆ†è¯ï¼šæ‰§è¡Œjiebaåˆ†è¯
    tokens = jieba.lcut(text)
    
    # å¼€å¯å»åœç”¨è¯ï¼šè¿‡æ»¤åœç”¨è¯
    if enable_stopwords:
        stopwords = load_stopwords()
        tokens = [word for word in tokens if word not in stopwords]
    
    # æ‹¼æ¥ä¸ºç©ºæ ¼åˆ†éš”çš„å­—ç¬¦ä¸²ï¼ˆä¾¿äºä¿å­˜åˆ°CSVï¼Œä¹Ÿå¯è¿”å›åˆ—è¡¨ï¼‰
    return " ".join(tokens)

# ===================== 4. å·¥å…·å‡½æ•°ï¼šæ—¥å¿—é…ç½® =====================
def setup_logger(log_path):
    """é…ç½®æ—¥å¿—ï¼ˆæ§åˆ¶å°+æ–‡ä»¶ï¼ŒUTF-8ç¼–ç ï¼‰"""
    log_file = f"{log_path}_æ–‡æœ¬æ¸…æ´—æ—¥å¿—_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"
    logger = logging.getLogger("text_cleaner")
    logger.setLevel(logging.INFO)
    logger.handlers.clear()
    
    # æ—¥å¿—æ ¼å¼
    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s', datefmt='%Y-%m-%d %H:%M:%S')
    
    # æ§åˆ¶å°è¾“å‡º
    console_handler = logging.StreamHandler()
    console_handler.setFormatter(formatter)
    logger.addHandler(console_handler)
    
    # æ–‡ä»¶è¾“å‡ºï¼ˆUTF-8ç¼–ç ï¼‰
    file_handler = logging.FileHandler(log_file, encoding='utf-8')
    file_handler.setFormatter(formatter)
    logger.addHandler(file_handler)
    
    return logger, log_file

# ===================== 5. æ ¸å¿ƒæ¸…æ´—å‡½æ•°ï¼ˆæ•´åˆæ‰€æœ‰æ¨¡å—ï¼‰ =====================
def clean_text_data(
    input_path, 
    output_path, 
    log_path="æ–‡æœ¬æ¸…æ´—æ—¥å¿—",
    enable_noise=DEFAULT_ENABLE_NOISE,
    enable_cut=DEFAULT_ENABLE_CUT,
    enable_stopwords=DEFAULT_ENABLE_STOPWORDS,
    text_column="content"  # æ–‡æœ¬åˆ—åï¼ˆé€‚é…æ–°é—»çš„content/æ­£æ–‡åˆ—ï¼‰
):
    """
    é€šç”¨æ–‡æœ¬æ¸…æ´—æ ¸å¿ƒå‡½æ•°ï¼ˆæ•´åˆæ­£åˆ™å»å™ª+åˆ†è¯+å»åœç”¨è¯ï¼‰
    :param input_path: è¾“å…¥CSVæ–‡ä»¶è·¯å¾„
    :param output_path: è¾“å‡ºCSVæ–‡ä»¶è·¯å¾„
    :param log_path: æ—¥å¿—æ–‡ä»¶å‰ç¼€
    :param enable_noise: æ˜¯å¦å¼€å¯æ­£åˆ™å»å™ª
    :param enable_cut: æ˜¯å¦å¼€å¯åˆ†è¯
    :param enable_stopwords: æ˜¯å¦å»åœç”¨è¯ï¼ˆä»…åˆ†è¯å¼€å¯æ—¶ç”Ÿæ•ˆï¼‰
    :param text_column: å¾…æ¸…æ´—çš„æ–‡æœ¬åˆ—å
    :return: æ¸…æ´—åçš„æ•°æ®æ¡†ã€æ—¥å¿—æ–‡ä»¶è·¯å¾„ã€æ¸…æ´—ç‡
    """
    # åˆå§‹åŒ–æ—¥å¿—
    logger, log_file = setup_logger(log_path)
    logger.info("="*80)
    logger.info("å¼€å§‹æ‰§è¡Œé€šç”¨æ–‡æœ¬æ¸…æ´—æµç¨‹ï¼ˆé€‚é…ä¸­æ–‡æ–°é—»ï¼‰")
    logger.info(f"é…ç½®ï¼šæ­£åˆ™å»å™ª={enable_noise} | åˆ†è¯={enable_cut} | å»åœç”¨è¯={enable_stopwords}")
    logger.info(f"è¾“å…¥æ–‡ä»¶ï¼š{input_path} | è¾“å‡ºæ–‡ä»¶ï¼š{output_path} | æ–‡æœ¬åˆ—ï¼š{text_column}")
    logger.info("="*80)

    try:
        # æ­¥éª¤1ï¼šåŠ è½½æ•°æ®
        logger.info("ã€æ­¥éª¤1ï¼šåŠ è½½åŸå§‹æ•°æ®ã€‘")
        df = pd.read_csv(input_path, encoding='utf-8', on_bad_lines='skip')
        original_count = len(df)
        logger.info(f"åŸå§‹æ•°æ®é‡ï¼š{original_count} æ¡")
        
        # æ£€æŸ¥æ–‡æœ¬åˆ—æ˜¯å¦å­˜åœ¨
        if text_column not in df.columns:
            raise ValueError(f"æ•°æ®ç¼ºå°‘æŒ‡å®šçš„æ–‡æœ¬åˆ—ï¼š{text_column}ï¼Œè¯·æ£€æŸ¥åˆ—å")
        
        # æ­¥éª¤2ï¼šåŸºç¡€æ¸…æ´—ï¼ˆå»é‡+åˆ ç©ºï¼‰
        logger.info("ã€æ­¥éª¤2ï¼šåŸºç¡€æ¸…æ´—ï¼ˆå»é‡+åˆ é™¤ç©ºæ–‡æœ¬ï¼‰ã€‘")
        # å»é‡ï¼ˆåŸºäºæ–‡æœ¬åˆ—ï¼‰
        df = df.drop_duplicates(subset=[text_column], keep='first')
        # åˆ é™¤ç©ºæ–‡æœ¬
        df = df[df[text_column].notna()]
        df = df[df[text_column].str.strip() != '']
        basic_clean_count = len(df)
        logger.info(f"åŸºç¡€æ¸…æ´—åæ•°æ®é‡ï¼š{basic_clean_count} æ¡ï¼ˆåˆ é™¤ {original_count - basic_clean_count} æ¡æ— æ•ˆæ•°æ®ï¼‰")
        
        # æ­¥éª¤3ï¼šæ­£åˆ™å»å™ªï¼ˆå¯é€‰ï¼‰
        if enable_noise:
            logger.info("ã€æ­¥éª¤3ï¼šæ­£åˆ™å»å™ªï¼ˆå»é™¤HTML/Emoji/ç‰¹æ®Šç¬¦å·/å¤šä½™ç©ºæ ¼ï¼‰ã€‘")
            df['cleaned_noise'] = df[text_column].apply(clean_text_noise)
            # å»å™ªåå†æ¬¡åˆ ç©ºï¼ˆé¿å…å»å™ªåæ–‡æœ¬ä¸ºç©ºï¼‰
            df = df[df['cleaned_noise'].str.strip() != '']
            noise_clean_count = len(df)
            logger.info(f"æ­£åˆ™å»å™ªåæ•°æ®é‡ï¼š{noise_clean_count} æ¡ï¼ˆåˆ é™¤ {basic_clean_count - noise_clean_count} æ¡æ— æ•ˆæ•°æ®ï¼‰")
            # ä¸´æ—¶æ–‡æœ¬åˆ—ï¼šåç»­åˆ†è¯åŸºäºå»å™ªåçš„æ–‡æœ¬
            temp_text_col = 'cleaned_noise'
        else:
            logger.info("ã€æ­¥éª¤3ï¼šè·³è¿‡æ­£åˆ™å»å™ªã€‘")
            df['cleaned_noise'] = df[text_column]
            temp_text_col = text_column
            noise_clean_count = basic_clean_count
        
        # æ­¥éª¤4ï¼šåˆ†è¯+å»åœç”¨è¯ï¼ˆå¯é€‰ï¼‰
        if enable_cut:
            logger.info(f"ã€æ­¥éª¤4ï¼šjiebaåˆ†è¯ï¼ˆå»åœç”¨è¯={enable_stopwords}ï¼‰ã€‘")
            df['final_cleaned'] = df[temp_text_col].apply(
                lambda x: cn_text_cut(x, enable_cut=True, enable_stopwords=enable_stopwords)
            )
        else:
            logger.info("ã€æ­¥éª¤4ï¼šè·³è¿‡åˆ†è¯ï¼Œä½¿ç”¨å»å™ªåæ–‡æœ¬ä½œä¸ºæœ€ç»ˆç»“æœã€‘")
            df['final_cleaned'] = df[temp_text_col]
        
        # æ­¥éª¤5ï¼šæœ€ç»ˆè¿‡æ»¤ï¼ˆåˆ é™¤åˆ†è¯åä¸ºç©ºçš„æ–‡æœ¬ï¼‰
        df = df[df['final_cleaned'].str.strip() != '']
        final_count = len(df)
        logger.info(f"æœ€ç»ˆæ¸…æ´—åæ•°æ®é‡ï¼š{final_count} æ¡")
        
        # æ­¥éª¤6ï¼šè®¡ç®—æ¸…æ´—ç‡
        clean_rate = round(((original_count - final_count) / original_count) * 100, 2)
        logger.info("="*80)
        logger.info("âœ… æ–‡æœ¬æ¸…æ´—æµç¨‹å®Œæˆï¼")
        logger.info(f"æ ¸å¿ƒç»Ÿè®¡ï¼šåŸå§‹ {original_count} æ¡ â†’ æœ€ç»ˆ {final_count} æ¡ | æ¸…æ´—ç‡ {clean_rate}%")
        logger.info("="*80)
        
        # æ­¥éª¤7ï¼šä¿å­˜ç»“æœï¼ˆä¿ç•™åŸå§‹åˆ—+æ¸…æ´—åˆ—ï¼‰
        df.to_csv(output_path, index=False, encoding='utf-8')
        logger.info(f"ğŸ“ æ¸…æ´—ç»“æœå·²ä¿å­˜è‡³ï¼š{output_path}")
        
        return df, log_file, clean_rate

    except Exception as e:
        logger.error(f"âŒ æ¸…æ´—æµç¨‹å¤±è´¥ï¼š{str(e)}", exc_info=True)
        logger.error(f"å¼‚å¸¸è¯¦æƒ…ï¼š\n{traceback.format_exc()}")
        return None, log_file, 0.0

# ===================== 6. å‘½ä»¤è¡Œå‚æ•°è§£æ =====================
def parse_args():
    """è§£æå‘½ä»¤è¡Œå‚æ•°ï¼ˆæ”¯æŒå„æ¨¡å—å¼€å…³ï¼‰"""
    parser = argparse.ArgumentParser(description="é€šç”¨æ–‡æœ¬æ¸…æ´—è„šæœ¬ï¼ˆé€‚é…ä¸­æ–‡æ–°é—»ï¼Œæ”¯æŒæ­£åˆ™å»å™ª+åˆ†è¯+å»åœç”¨è¯ï¼‰")
    # å¿…é€‰å‚æ•°
    parser.add_argument('-i', '--input', required=True, help="è¾“å…¥CSVæ–‡ä»¶è·¯å¾„ï¼ˆå¿…å¡«ï¼‰")
    parser.add_argument('-o', '--output', required=True, help="è¾“å‡ºæ¸…æ´—åCSVæ–‡ä»¶è·¯å¾„ï¼ˆå¿…å¡«ï¼‰")
    # å¯é€‰å‚æ•°ï¼šæ—¥å¿—
    parser.add_argument('-l', '--log', default="æ–‡æœ¬æ¸…æ´—æ—¥å¿—", help="æ—¥å¿—æ–‡ä»¶å‰ç¼€ï¼ˆé»˜è®¤ï¼šæ–‡æœ¬æ¸…æ´—æ—¥å¿—ï¼‰")
    # å¯é€‰å‚æ•°ï¼šæ–‡æœ¬åˆ—å
    parser.add_argument('-c', '--column', default="content", help="å¾…æ¸…æ´—çš„æ–‡æœ¬åˆ—åï¼ˆé»˜è®¤ï¼šcontentï¼‰")
    # å¯é€‰å‚æ•°ï¼šæ¨¡å—å¼€å…³ï¼ˆé»˜è®¤å¼€å¯æ‰€æœ‰ï¼‰
    parser.add_argument('--disable-noise', action='store_false', dest='enable_noise', help="å…³é—­æ­£åˆ™å»å™ªï¼ˆé»˜è®¤å¼€å¯ï¼‰")
    parser.add_argument('--disable-cut', action='store_false', dest='enable_cut', help="å…³é—­åˆ†è¯ï¼ˆé»˜è®¤å¼€å¯ï¼‰")
    parser.add_argument('--disable-stopwords', action='store_false', dest='enable_stopwords', help="å…³é—­å»åœç”¨è¯ï¼ˆé»˜è®¤å¼€å¯ï¼Œä»…åˆ†è¯å¼€å¯æ—¶ç”Ÿæ•ˆï¼‰")
    
    return parser.parse_args()

# ===================== 7. ä¸»å‡½æ•°ï¼ˆå‘½ä»¤è¡Œè¿è¡Œ/æµ‹è¯•ï¼‰ =====================
def main():
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    args = parse_args()
    
    # æ‰§è¡Œæ¸…æ´—
    df, log_file, clean_rate = clean_text_data(
        input_path=args.input,
        output_path=args.output,
        log_path=args.log,
        enable_noise=args.enable_noise,
        enable_cut=args.enable_cut,
        enable_stopwords=args.enable_stopwords,
        text_column=args.column
    )
    
    # è¾“å‡ºç»“æœ
    if df is not None:
        print(f"\nâœ… æ¸…æ´—æˆåŠŸï¼")
        print(f"ğŸ“Š æ ¸å¿ƒç»Ÿè®¡ï¼š")
        print(f"   - åŸå§‹æ•°æ®é‡ï¼š{pd.read_csv(args.input).shape[0]} æ¡")
        print(f"   - æ¸…æ´—åæ•°æ®é‡ï¼š{len(df)} æ¡")
        print(f"   - æ¸…æ´—ç‡ï¼š{clean_rate}%")
        print(f"\nğŸ“ æ¸…æ´—æ•ˆæœé¢„è§ˆï¼ˆå‰2æ¡ï¼‰ï¼š")
        for i in range(min(2, len(df))):
            print(f"\nã€åŸå§‹æ–‡æœ¬{i+1}ã€‘ï¼š\n{df[args.column].iloc[i][:150]}...")
            print(f"ã€æœ€ç»ˆæ¸…æ´—å{i+1}ã€‘ï¼š\n{df['final_cleaned'].iloc[i][:150]}...")
        print(f"\nğŸ“„ æ—¥å¿—æ–‡ä»¶è·¯å¾„ï¼š{log_file}")
    else:
        print(f"\nâŒ æ¸…æ´—å¤±è´¥ï¼è¯·æŸ¥çœ‹æ—¥å¿—æ–‡ä»¶æ’æŸ¥é—®é¢˜ï¼š{log_file}")

# ===================== 8. æµ‹è¯•æ¨¡å—ï¼ˆä¸­æ–‡æ–°é—»æ–‡æœ¬ï¼‰ =====================
def test_cn_news_clean():
    """æµ‹è¯•ï¼šç”Ÿæˆæ¨¡æ‹Ÿä¸­æ–‡æ–°é—»æ•°æ®å¹¶æ‰§è¡Œæ¸…æ´—"""
    print("="*80)
    print("ğŸ“Œ æ‰§è¡Œä¸­æ–‡æ–°é—»æ–‡æœ¬æ¸…æ´—æµ‹è¯•")
    print("="*80)
    
    # æ­¥éª¤1ï¼šç”Ÿæˆæ¨¡æ‹Ÿä¸­æ–‡æ–°é—»æ•°æ®ï¼ˆå«å™ªå£°ï¼šHTMLæ ‡ç­¾ã€Emojiã€å¤šä½™ç©ºæ ¼ã€åœç”¨è¯ï¼‰
    test_news_data = {
        'title': [
            "ã€å¤®è§†æ–°é—»ã€‘2025å¹´å…¨å›½ä¸¤ä¼šå¼€å¹•ğŸ˜€",
            "ç§‘æŠ€å·¨å¤´å‘å¸ƒæ–°æ¬¾AIèŠ¯ç‰‡ï¼Œæ€§èƒ½æå‡50%â˜…",
            "",  # ç©ºæ ‡é¢˜
            "ã€å¤®è§†æ–°é—»ã€‘2025å¹´å…¨å›½ä¸¤ä¼šå¼€å¹•ğŸ˜€",  # é‡å¤æ–°é—»
            "å¤šåœ°å‡ºå°æ¥¼å¸‚æ–°æ”¿ï¼Œæ”¯æŒåˆšæ€§è´­æˆ¿éœ€æ±‚"
        ],
        'content': [
            """<p>æœ¬æŠ¥è®°è€…ä»å›½åŠ¡é™¢æ–°é—»åŠè·æ‚‰<br/>ï¼Œ2025å¹´å…¨å›½ä¸¤ä¼šäº3æœˆ5æ—¥åœ¨åŒ—äº¬å¬å¼€ï¼Œç›¸å…³éƒ¨é—¨è¡¨ç¤ºï¼Œä»Šå¹´å°†é‡ç‚¹å…³æ³¨æ°‘ç”Ÿã€å°±ä¸šç­‰é¢†åŸŸã€‚</p> æ®æ‚‰ï¼Œæ­¤æ¬¡ä¼šè®®å‚ä¼šä»£è¡¨è¶…2000äººï¼Œè¦†ç›–å…¨å›½31ä¸ªçœå¸‚åŒºã€‚""",
            """<a href="https://tech.example.com">ç§‘æŠ€å·¨å¤´ABCå…¬å¸è¿‘æ—¥å‘å¸ƒäº†æ–°æ¬¾AIèŠ¯ç‰‡ï¼Œè¯¥èŠ¯ç‰‡çš„ç®—åŠ›ç›¸æ¯”ä¸Šä¸€ä»£æå‡50%ï¼Œç›¸å…³ä¸“å®¶è®¤ä¸ºï¼Œè¿™å°†æ¨åŠ¨äººå·¥æ™ºèƒ½è¡Œä¸šçš„å‘å±•ã€‚</a> ç›®å‰ï¼Œè¯¥èŠ¯ç‰‡å·²å¼€å§‹é‡äº§ã€‚""",
            "",  # ç©ºå†…å®¹
            """<p>æœ¬æŠ¥è®°è€…ä»å›½åŠ¡é™¢æ–°é—»åŠè·æ‚‰<br/>ï¼Œ2025å¹´å…¨å›½ä¸¤ä¼šäº3æœˆ5æ—¥åœ¨åŒ—äº¬å¬å¼€ï¼Œç›¸å…³éƒ¨é—¨è¡¨ç¤ºï¼Œä»Šå¹´å°†é‡ç‚¹å…³æ³¨æ°‘ç”Ÿã€å°±ä¸šç­‰é¢†åŸŸã€‚</p> æ®æ‚‰ï¼Œæ­¤æ¬¡ä¼šè®®å‚ä¼šä»£è¡¨è¶…2000äººï¼Œè¦†ç›–å…¨å›½31ä¸ªçœå¸‚åŒºã€‚""",
            """è¿‘æ—¥ï¼Œä¸Šæµ·ã€å¹¿å·ã€æ·±åœ³ç­‰å¤šåœ°å‘å¸ƒäº†æ–°çš„æ¥¼å¸‚è°ƒæ§æ”¿ç­–ï¼Œç›¸å…³éƒ¨é—¨æŒ‡å‡ºï¼Œæ–°æ”¿å°†æ”¯æŒåˆšæ€§å’Œæ”¹å–„æ€§è´­æˆ¿éœ€æ±‚ï¼ŒåŒæ—¶ä¿æŒæˆ¿åœ°äº§å¸‚åœºçš„ç¨³å®šã€‚æ®äº†è§£ï¼Œéƒ¨åˆ†åŸå¸‚å·²ä¸‹è°ƒæˆ¿è´·åˆ©ç‡ã€‚"""
        ]
    }
    # ä¿å­˜ä¸ºæµ‹è¯•CSV
    test_input = "test_cn_news.csv"
    test_output = "test_cn_news_cleaned.csv"
    pd.DataFrame(test_news_data).to_csv(test_input, index=False, encoding='utf-8')
    print(f"âœ… ç”Ÿæˆæ¨¡æ‹Ÿä¸­æ–‡æ–°é—»æ•°æ®ï¼š{test_input}")
    
    # æ­¥éª¤2ï¼šæ‰§è¡Œæ¸…æ´—ï¼ˆå¼€å¯æ‰€æœ‰æ¨¡å—ï¼‰
    df, log_file, clean_rate = clean_text_data(
        input_path=test_input,
        output_path=test_output,
        log_path="ä¸­æ–‡æ–°é—»æ¸…æ´—æµ‹è¯•",
        enable_noise=True,
        enable_cut=True,
        enable_stopwords=True,
        text_column="content"  # æ¸…æ´—æ­£æ–‡åˆ—
    )
    
    # æ­¥éª¤3ï¼šè¾“å‡ºæµ‹è¯•ç»“æœ
    if df is not None:
        print(f"\nâœ… ä¸­æ–‡æ–°é—»æ¸…æ´—æµ‹è¯•å®Œæˆï¼")
        print(f"ğŸ“Š æµ‹è¯•ç»Ÿè®¡ï¼šåŸå§‹5æ¡ â†’ æ¸…æ´—å{len(df)}æ¡ | æ¸…æ´—ç‡{clean_rate}%")
        print(f"\nğŸ“ æ¸…æ´—æ•ˆæœç¤ºä¾‹ï¼ˆç¬¬ä¸€æ¡æ–°é—»ï¼‰ï¼š")
        print(f"åŸå§‹æ­£æ–‡ï¼š\n{df['content'].iloc[0][:200]}...")
        print(f"æ¸…æ´—åæ­£æ–‡ï¼š\n{df['final_cleaned'].iloc[0]}")
        print(f"\nğŸ“ æ¸…æ´—ç»“æœæ–‡ä»¶ï¼š{test_output}")
        print(f"ğŸ“„ æµ‹è¯•æ—¥å¿—æ–‡ä»¶ï¼š{log_file}")
    else:
        print(f"\nâŒ ä¸­æ–‡æ–°é—»æ¸…æ´—æµ‹è¯•å¤±è´¥ï¼")

# ===================== å…¥å£å‡½æ•° =====================
if __name__ == "__main__":
    try:
        # ä¼˜å…ˆæ‰§è¡Œå‘½ä»¤è¡Œæ¨¡å¼
        main()
    except SystemExit:
        # æ— å‘½ä»¤è¡Œå‚æ•°æ—¶ï¼Œæ‰§è¡Œä¸­æ–‡æ–°é—»æµ‹è¯•
        test_cn_news_clean()
    except Exception as e:
        print(f"\nâŒ è¿è¡Œå‡ºé”™ï¼š{str(e)}")
        print(f"å¼‚å¸¸è¯¦æƒ…ï¼š\n{traceback.format_exc()}")
```

### 3. æµ‹è¯•ä¸ä½¿ç”¨è¯´æ˜
#### ï¼ˆ1ï¼‰è‡ªåŠ¨æµ‹è¯•ï¼ˆä¸­æ–‡æ–°é—»ï¼‰
ç›´æ¥è¿è¡Œè„šæœ¬ï¼Œæ— éœ€ä¼ å…¥ä»»ä½•å‚æ•°ï¼Œä¼šè‡ªåŠ¨ç”Ÿæˆ**æ¨¡æ‹Ÿä¸­æ–‡æ–°é—»æ•°æ®**å¹¶æ‰§è¡Œæ¸…æ´—ï¼Œè¾“å‡ºå¦‚ä¸‹ï¼ˆç¤ºä¾‹ï¼‰ï¼š
```
========================================
ğŸ“Œ æ‰§è¡Œä¸­æ–‡æ–°é—»æ–‡æœ¬æ¸…æ´—æµ‹è¯•
========================================
âœ… ç”Ÿæˆæ¨¡æ‹Ÿä¸­æ–‡æ–°é—»æ•°æ®ï¼štest_cn_news.csv
========================================
å¼€å§‹æ‰§è¡Œé€šç”¨æ–‡æœ¬æ¸…æ´—æµç¨‹ï¼ˆé€‚é…ä¸­æ–‡æ–°é—»ï¼‰
é…ç½®ï¼šæ­£åˆ™å»å™ª=True | åˆ†è¯=True | å»åœç”¨è¯=True
è¾“å…¥æ–‡ä»¶ï¼štest_cn_news.csv | è¾“å‡ºæ–‡ä»¶ï¼štest_cn_news_cleaned.csv | æ–‡æœ¬åˆ—ï¼šcontent
========================================
ã€æ­¥éª¤1ï¼šåŠ è½½åŸå§‹æ•°æ®ã€‘
åŸå§‹æ•°æ®é‡ï¼š5 æ¡
ã€æ­¥éª¤2ï¼šåŸºç¡€æ¸…æ´—ï¼ˆå»é‡+åˆ é™¤ç©ºæ–‡æœ¬ï¼‰ã€‘
åŸºç¡€æ¸…æ´—åæ•°æ®é‡ï¼š3 æ¡ï¼ˆåˆ é™¤ 2 æ¡æ— æ•ˆæ•°æ®ï¼‰
ã€æ­¥éª¤3ï¼šæ­£åˆ™å»å™ªï¼ˆå»é™¤HTML/Emoji/ç‰¹æ®Šç¬¦å·/å¤šä½™ç©ºæ ¼ï¼‰ã€‘
âœ… æˆåŠŸåŠ è½½åœç”¨è¯è¡¨ï¼ˆæœ¬åœ°æ–‡ä»¶+å†…ç½®ï¼‰ï¼Œå…± 45 ä¸ªåœç”¨è¯
æ­£åˆ™å»å™ªåæ•°æ®é‡ï¼š3 æ¡ï¼ˆåˆ é™¤ 0 æ¡æ— æ•ˆæ•°æ®ï¼‰
ã€æ­¥éª¤4ï¼šjiebaåˆ†è¯ï¼ˆå»åœç”¨è¯=Trueï¼‰ã€‘
========================================
âœ… æ–‡æœ¬æ¸…æ´—æµç¨‹å®Œæˆï¼
æ ¸å¿ƒç»Ÿè®¡ï¼šåŸå§‹ 5 æ¡ â†’ æœ€ç»ˆ 3 æ¡ | æ¸…æ´—ç‡ 40.0%
========================================
ğŸ“ æ¸…æ´—ç»“æœå·²ä¿å­˜è‡³ï¼štest_cn_news_cleaned.csv

âœ… ä¸­æ–‡æ–°é—»æ¸…æ´—æµ‹è¯•å®Œæˆï¼
ğŸ“Š æµ‹è¯•ç»Ÿè®¡ï¼šåŸå§‹5æ¡ â†’ æ¸…æ´—å3æ¡ | æ¸…æ´—ç‡40.0%

ğŸ“ æ¸…æ´—æ•ˆæœç¤ºä¾‹ï¼ˆç¬¬ä¸€æ¡æ–°é—»ï¼‰ï¼š
åŸå§‹æ­£æ–‡ï¼š
<p>æœ¬æŠ¥è®°è€…ä»å›½åŠ¡é™¢æ–°é—»åŠè·æ‚‰<br/>ï¼Œ2025å¹´å…¨å›½ä¸¤ä¼šäº3æœˆ5æ—¥åœ¨åŒ—äº¬å¬å¼€ï¼Œç›¸å…³éƒ¨é—¨è¡¨ç¤ºï¼Œä»Šå¹´å°†é‡ç‚¹å…³æ³¨æ°‘ç”Ÿã€å°±ä¸šç­‰é¢†åŸŸã€‚</p> æ®æ‚‰ï¼Œæ­¤æ¬¡ä¼šè®®å‚ä¼šä»£è¡¨è¶…2000äººï¼Œè¦†ç›–å…¨å›½31ä¸ªçœå¸‚åŒºã€‚...
æ¸…æ´—åæ­£æ–‡ï¼š
å›½åŠ¡é™¢æ–°é—»åŠ 2025å¹´ å…¨å›½ä¸¤ä¼š 3æœˆ5æ—¥ åŒ—äº¬ å¬å¼€ ä»Šå¹´ é‡ç‚¹ å…³æ³¨ æ°‘ç”Ÿ å°±ä¸š é¢†åŸŸ æ­¤æ¬¡ ä¼šè®® å‚ä¼š ä»£è¡¨ 2000äºº è¦†ç›– å…¨å›½ 31ä¸ª çœå¸‚åŒº
```

#### ï¼ˆ2ï¼‰å‘½ä»¤è¡Œè¿è¡Œï¼ˆè‡ªå®šä¹‰å‚æ•°ï¼‰
é’ˆå¯¹çœŸå®ä¸­æ–‡æ–°é—»CSVæ–‡ä»¶ï¼Œå¯é€šè¿‡å‚æ•°çµæ´»æ§åˆ¶æ¨¡å—å¯åœï¼š
```bash
# ç¤ºä¾‹1ï¼šå¼€å¯æ‰€æœ‰æ¨¡å—ï¼ˆé»˜è®¤ï¼‰
python text_cleaner.py -i real_news.csv -o real_news_cleaned.csv -c content

# ç¤ºä¾‹2ï¼šä»…å¼€å¯æ­£åˆ™å»å™ªï¼Œå…³é—­åˆ†è¯å’Œå»åœç”¨è¯
python text_cleaner.py -i real_news.csv -o real_news_cleaned.csv -c content --disable-cut --disable-stopwords

# ç¤ºä¾‹3ï¼šå¼€å¯æ­£åˆ™å»å™ªå’Œåˆ†è¯ï¼Œå…³é—­å»åœç”¨è¯
python text_cleaner.py -i real_news.csv -o real_news_cleaned.csv -c content --disable-stopwords
```

### 4. æ€»ç»“
1. **æ ¸å¿ƒæ‹“å±•ç‚¹**ï¼š
   - æ•´åˆã€Œæ­£åˆ™å»å™ªâ†’åˆ†è¯â†’å»åœç”¨è¯ã€ä¸‰å¤§æ¨¡å—ï¼Œé€‚é…ä¸­æ–‡æ–°é—»çš„å™ªå£°ç‰¹ç‚¹ï¼ˆHTMLæ ‡ç­¾ã€æ–°é—»ä¸“å±åœç”¨è¯ç­‰ï¼‰ï¼›
   - æ–°å¢`--disable-noise/--disable-cut/--disable-stopwords`å‚æ•°ï¼Œçµæ´»æ§åˆ¶å„æ¨¡å—å¯åœï¼›
   - å†…ç½®æ–°é—»ä¸“å±åœç”¨è¯è¡¨ï¼Œå…¼é¡¾é€šç”¨æ€§å’Œåœºæ™¯é€‚é…æ€§ã€‚
2. **å…³é”®ç‰¹æ€§**ï¼š
   - æ¨¡å—åŒ–è®¾è®¡ï¼šå„åŠŸèƒ½è§£è€¦ï¼Œä¾¿äºå•ç‹¬ä¿®æ”¹/æ‹“å±•ï¼ˆå¦‚æ–°å¢å…¶ä»–åˆ†è¯å·¥å…·ã€è‡ªå®šä¹‰å»å™ªè§„åˆ™ï¼‰ï¼›
   - é²æ£’æ€§ï¼šç©ºå€¼å¤„ç†ã€æ–‡ä»¶ç¼ºå¤±å…œåº•ã€å¼‚å¸¸æ—¥å¿—è®°å½•ï¼Œé¿å…è„šæœ¬å´©æºƒï¼›
   - æ˜“ç”¨æ€§ï¼šè‡ªåŠ¨æµ‹è¯•æ¨¡å—+å‘½ä»¤è¡Œå‚æ•°ï¼Œæ–°æ‰‹å¯å¿«é€Ÿä¸Šæ‰‹ã€‚
3. **é€‚é…åœºæ™¯**ï¼š
   - å¯ç›´æ¥ç”¨äºä¸­æ–‡æ–°é—»ã€å½±è¯„ã€ç¤¾äº¤åª’ä½“æ–‡æœ¬ç­‰åœºæ™¯çš„æ¸…æ´—ï¼Œä»…éœ€è°ƒæ•´`text_column`å‚æ•°å’Œåœç”¨è¯è¡¨å³å¯ã€‚

è¯¥è„šæœ¬å·²å…·å¤‡é€šç”¨æ–‡æœ¬æ¸…æ´—çš„æ ¸å¿ƒèƒ½åŠ›ï¼Œä½ å¯æ ¹æ®å®é™…éœ€æ±‚ï¼ˆå¦‚æ–°å¢å®ä½“è¯†åˆ«ã€å…³é”®è¯æå–ï¼‰è¿›ä¸€æ­¥æ‹“å±•ï¼