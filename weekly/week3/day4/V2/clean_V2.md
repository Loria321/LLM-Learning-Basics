### 1. éœ€æ±‚ç¡®è®¤
ä½ éœ€è¦å¯¹é€šç”¨æ¸…æ´—è„šæœ¬V1.0åšä¸‰å¤§ä¼˜åŒ–ï¼šâ‘  å¼ºåŒ–å¼‚å¸¸å¤„ç†ï¼ˆè¦†ç›–æ–‡ä»¶ä¸å­˜åœ¨ã€æ ¼å¼é”™è¯¯ç­‰åœºæ™¯ï¼‰ï¼›â‘¡ å¢åŠ `argparse`æ”¯æŒç»ˆç«¯å‘½ä»¤è¡Œè¿è¡Œï¼›â‘¢ é€‚é…ä¸åŒå¼‚å¸¸åœºæ™¯æµ‹è¯•ï¼ˆå¦‚ä¼ å…¥Excelæ–‡ä»¶ï¼‰ã€‚æˆ‘ä¼šæä¾›**å®Œæ•´ä¼˜åŒ–åä»£ç **ï¼Œå¹¶è¯¦ç»†è¯´æ˜å…³é”®ä¼˜åŒ–ç‚¹å’Œå¼‚å¸¸åœºæ™¯æµ‹è¯•æ–¹æ³•ã€‚

### 2. å®Œæ•´ä¼˜åŒ–åè„šæœ¬ï¼ˆV2.0ï¼‰
```python
import pandas as pd
import numpy as np
import logging
from datetime import datetime
import os
import argparse  # æ–°å¢ï¼šå‘½ä»¤è¡Œå‚æ•°æ”¯æŒ
import traceback  # æ–°å¢ï¼šè¯¦ç»†å¼‚å¸¸æ ˆè¿½è¸ª

# ===================== 1. æ—¥å¿—é…ç½®ï¼ˆä¿ç•™å¹¶ä¼˜åŒ–ï¼‰ =====================
def setup_logger(log_path):
    """é…ç½®æ—¥å¿—ï¼šåŒæ—¶è¾“å‡ºåˆ°æ§åˆ¶å°å’Œæ—¥å¿—æ–‡ä»¶ï¼Œè®°å½•æ¸…æ´—å…¨æµç¨‹"""
    # æ—¥å¿—æ–‡ä»¶ååŒ…å«æ—¶é—´æˆ³ï¼Œé¿å…è¦†ç›–
    log_file = f"{log_path}_æ¸…æ´—æ—¥å¿—_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"
    
    # é…ç½®æ—¥å¿—æ ¼å¼
    logger = logging.getLogger("data_cleaner")
    logger.setLevel(logging.INFO)
    # æ¸…ç©ºå·²æœ‰å¤„ç†å™¨ï¼ˆé¿å…é‡å¤æ‰“å°ï¼‰
    logger.handlers.clear()
    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s', datefmt='%Y-%m-%d %H:%M:%S')
    
    # æ§åˆ¶å°å¤„ç†å™¨
    console_handler = logging.StreamHandler()
    console_handler.setFormatter(formatter)
    # æ–‡ä»¶å¤„ç†å™¨
    file_handler = logging.FileHandler(log_file, encoding='utf-8')
    file_handler.setFormatter(formatter)
    
    logger.addHandler(console_handler)
    logger.addHandler(file_handler)
    
    return logger, log_file

# ===================== 2. æ ¸å¿ƒæ¸…æ´—å‡½æ•°ï¼ˆå¼ºåŒ–å¼‚å¸¸å¤„ç†ï¼‰ =====================
def clean_csv_data(
    input_path,          # è¾“å…¥CSVæ–‡ä»¶è·¯å¾„
    output_path,         # è¾“å‡ºæ¸…æ´—åCSVè·¯å¾„
    log_path="æ¸…æ´—æ—¥å¿—",  # æ—¥å¿—æ–‡ä»¶åŸºç¡€è·¯å¾„
    duplicate_threshold=5.0,  # é‡å¤è¡Œå æ¯”é˜ˆå€¼ï¼ˆ%ï¼‰ï¼Œè¶…è¿‡åˆ™ç»ˆæ­¢
    missing_fill_strategy="auto",  # ç¼ºå¤±å€¼å¡«å……ç­–ç•¥ï¼šauto/mean/median/mode/drop
    missing_col_threshold=30.0,    # åˆ—ç¼ºå¤±ç‡é˜ˆå€¼ï¼ˆ%ï¼‰ï¼Œè¶…è¿‡åˆ™åˆ é™¤åˆ—
    outlier_method="IQR",          # å¼‚å¸¸å€¼åˆ¤å®šæ–¹æ³•ï¼šIQR/3Ïƒ
    outlier_threshold=5.0          # å¼‚å¸¸å€¼å æ¯”é˜ˆå€¼ï¼ˆ%ï¼‰ï¼Œè¶…è¿‡åˆ™æç¤º
):
    """
    é€šç”¨CSVæ•°æ®æ¸…æ´—å‡½æ•°ï¼ˆæ”¯æŒå‚æ•°é…ç½®+å¼ºåŒ–å¼‚å¸¸å¤„ç†ï¼‰
    :param input_path: è¾“å…¥CSVæ–‡ä»¶è·¯å¾„
    :param output_path: è¾“å‡ºæ¸…æ´—åCSVè·¯å¾„
    :param log_path: æ—¥å¿—æ–‡ä»¶ä¿å­˜åŸºç¡€è·¯å¾„
    :param duplicate_threshold: é‡å¤è¡Œå æ¯”é˜ˆå€¼ï¼ˆ%ï¼‰ï¼Œ>è¯¥å€¼åˆ™ç»ˆæ­¢æ¸…æ´—
    :param missing_fill_strategy: ç¼ºå¤±å€¼å¡«å……ç­–ç•¥
                                  - autoï¼šæ•°å€¼åˆ—ç”¨medianï¼Œç±»åˆ«åˆ—ç”¨mode
                                  - meanï¼šæ•°å€¼åˆ—ç”¨å‡å€¼
                                  - medianï¼šæ•°å€¼åˆ—ç”¨ä¸­ä½æ•°
                                  - modeï¼šç±»åˆ«åˆ—ç”¨ä¼—æ•°
                                  - dropï¼šåˆ é™¤æ‰€æœ‰ç¼ºå¤±è¡Œ
    :param missing_col_threshold: åˆ—ç¼ºå¤±ç‡é˜ˆå€¼ï¼ˆ%ï¼‰ï¼Œ>è¯¥å€¼åˆ é™¤åˆ—
    :param outlier_method: å¼‚å¸¸å€¼åˆ¤å®šæ–¹æ³•ï¼ˆIQR/3Ïƒï¼‰
    :param outlier_threshold: å¼‚å¸¸å€¼å æ¯”é˜ˆå€¼ï¼ˆ%ï¼‰ï¼Œ>è¯¥å€¼ä»…æç¤ºä¸å¤„ç†
    :return: æ¸…æ´—åDataFrameã€æ—¥å¿—æ–‡ä»¶è·¯å¾„ | å¼‚å¸¸æ—¶è¿”å›None, æ—¥å¿—è·¯å¾„
    """
    # åˆå§‹åŒ–æ—¥å¿—
    logger, log_file = setup_logger(log_path)
    logger.info("="*50)
    logger.info("å¼€å§‹æ‰§è¡Œæ•°æ®æ¸…æ´—æµç¨‹")
    logger.info(f"è¾“å…¥æ–‡ä»¶ï¼š{input_path}")
    logger.info(f"é…ç½®å‚æ•°ï¼šé‡å¤è¡Œé˜ˆå€¼={duplicate_threshold}% | ç¼ºå¤±åˆ—é˜ˆå€¼={missing_col_threshold}% | ç¼ºå¤±å¡«å……ç­–ç•¥={missing_fill_strategy} | å¼‚å¸¸å€¼æ–¹æ³•={outlier_method}")
    logger.info("="*50)

    try:
        # -------------------- æ–°å¢ï¼šå‰ç½®æ ¼å¼æ ¡éªŒ --------------------
        logger.info("ã€å‰ç½®æ ¡éªŒã€‘æ£€æŸ¥æ–‡ä»¶æ ¼å¼å’Œå­˜åœ¨æ€§")
        # 1. æ£€æŸ¥è¾“å…¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(input_path):
            raise FileNotFoundError(f"è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨ï¼š{input_path}")
        
        # 2. æ£€æŸ¥è¾“å…¥æ–‡ä»¶æ ¼å¼ï¼ˆä»…æ”¯æŒCSVï¼‰
        if not input_path.lower().endswith('.csv'):
            raise ValueError(f"è¾“å…¥æ–‡ä»¶æ ¼å¼é”™è¯¯ï¼ä»…æ”¯æŒCSVæ–‡ä»¶ï¼Œå½“å‰æ–‡ä»¶ï¼š{input_path}")
        
        # 3. æ£€æŸ¥è¾“å‡ºæ–‡ä»¶æ ¼å¼ï¼ˆä»…æ”¯æŒCSVï¼‰
        if not output_path.lower().endswith('.csv'):
            raise ValueError(f"è¾“å‡ºæ–‡ä»¶æ ¼å¼é”™è¯¯ï¼ä»…æ”¯æŒCSVæ–‡ä»¶ï¼Œå½“å‰æ–‡ä»¶ï¼š{output_path}")

        # -------------------- æ­¥éª¤1ï¼šæ•°æ®åŠ è½½ --------------------
        logger.info("ã€æ­¥éª¤1ï¼šæ•°æ®åŠ è½½ã€‘")
        df = pd.read_csv(input_path, encoding='utf-8')
        original_shape = df.shape
        logger.info(f"åŸå§‹æ•°æ®ç»´åº¦ï¼š{original_shape[0]}è¡Œ Ã— {original_shape[1]}åˆ—")
        
        if df.empty:
            raise ValueError("åŠ è½½çš„CSVæ–‡ä»¶ä¸ºç©ºï¼Œæ— æ•°æ®å¯æ¸…æ´—")

        # -------------------- æ­¥éª¤2ï¼šæ¢ç´¢æ€§åˆ†æï¼ˆæ—¥å¿—è®°å½•ï¼Œä¿®å¤é‡å¤æ‰“å°ï¼‰ --------------------
        logger.info("\nã€æ­¥éª¤2ï¼šæ¢ç´¢æ€§åˆ†æã€‘")
        # æ•°æ®ç±»å‹
        logger.info(f"æ•°æ®ç±»å‹åˆ†å¸ƒï¼š\n{df.dtypes.to_string()}")
        # ç¼ºå¤±å€¼ç»Ÿè®¡
        missing_sum = df.isnull().sum()
        missing_rate = (missing_sum / len(df) * 100).round(2)
        missing_info = missing_rate[missing_rate > 0].to_string() if any(missing_rate > 0) else "æ— ç¼ºå¤±å€¼"
        logger.info(f"ç¼ºå¤±å€¼åˆ†å¸ƒï¼ˆåˆ—ï¼‰ï¼š\n{missing_info}")
        # æè¿°æ€§ç»Ÿè®¡ï¼ˆä»…æ‰“å°ä¸€æ¬¡ï¼‰
        numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns
        if len(numeric_cols) > 0:
            desc_stats = df[numeric_cols].describe().round(2).to_string()
            logger.info(f"æ•°å€¼åˆ—æè¿°æ€§ç»Ÿè®¡ï¼š\n{desc_stats}")

        # -------------------- æ­¥éª¤3ï¼šå»é‡ --------------------
        logger.info("\nã€æ­¥éª¤3ï¼šå»é‡å¤„ç†ã€‘")
        duplicate_count = df.duplicated().sum()
        duplicate_rate = (duplicate_count / len(df) * 100).round(2)
        logger.info(f"é‡å¤è¡Œæ•°é‡ï¼š{duplicate_count} | é‡å¤è¡Œå æ¯”ï¼š{duplicate_rate}%")
        
        if duplicate_rate > duplicate_threshold:
            raise ValueError(f"é‡å¤è¡Œå æ¯”ï¼ˆ{duplicate_rate}%ï¼‰è¶…è¿‡é˜ˆå€¼ï¼ˆ{duplicate_threshold}%ï¼‰ï¼Œç»ˆæ­¢æ¸…æ´—")
        elif duplicate_count > 0:
            df = df.drop_duplicates(keep='first')
            logger.info(f"å·²åˆ é™¤é‡å¤è¡Œï¼Œå½“å‰æ•°æ®ç»´åº¦ï¼š{df.shape[0]}è¡Œ Ã— {df.shape[1]}åˆ—")

        # -------------------- æ­¥éª¤4ï¼šç¼ºå¤±å€¼å¤„ç† --------------------
        logger.info("\nã€æ­¥éª¤4ï¼šç¼ºå¤±å€¼å¤„ç†ã€‘")
        # å…ˆå¤„ç†åˆ—ç¼ºå¤±ç‡è¶…è¿‡é˜ˆå€¼çš„åˆ—
        for col in df.columns:
            col_missing_rate = (df[col].isnull().sum() / len(df) * 100).round(2)
            if col_missing_rate > missing_col_threshold:
                logger.info(f"åˆ—[{col}]ç¼ºå¤±ç‡{col_missing_rate}% > é˜ˆå€¼{missing_col_threshold}%ï¼Œåˆ é™¤è¯¥åˆ—")
                df = df.drop(columns=[col])
                continue
            
            # å¤„ç†åˆ—å†…ç¼ºå¤±å€¼
            if df[col].isnull().sum() == 0:
                continue
            
            if missing_fill_strategy == "drop":
                df = df.dropna(subset=[col])
                logger.info(f"åˆ—[{col}]ï¼šåˆ é™¤ç¼ºå¤±è¡Œï¼Œå½“å‰è¡Œæ•°ï¼š{len(df)}")
            else:
                # æ ¹æ®ç­–ç•¥é€‰æ‹©å¡«å……å€¼
                if df[col].dtype in ['int64', 'float64']:
                    if missing_fill_strategy == "mean":
                        fill_val = df[col].mean().round(2)
                    elif missing_fill_strategy == "median":
                        fill_val = df[col].median()
                    else:  # auto/é»˜è®¤
                        fill_val = df[col].median()
                else:
                    fill_val = df[col].mode()[0]  # ç±»åˆ«åˆ—ç”¨ä¼—æ•°
                
                df[col] = df[col].fillna(fill_val)
                logger.info(f"åˆ—[{col}]ï¼šå¡«å……ç¼ºå¤±å€¼ï¼ˆç­–ç•¥={missing_fill_strategy} | å¡«å……å€¼={fill_val}ï¼‰")

        # -------------------- æ­¥éª¤5ï¼šå¼‚å¸¸å€¼å¤„ç†ï¼ˆä»…æ•°å€¼åˆ—ï¼‰ --------------------
        logger.info("\nã€æ­¥éª¤5ï¼šå¼‚å¸¸å€¼å¤„ç†ã€‘")
        for col in numeric_cols:
            if col not in df.columns:  # é¿å…åˆ—å·²è¢«åˆ é™¤
                continue
            
            # å¼‚å¸¸å€¼åˆ¤å®š
            if outlier_method == "3Ïƒ":
                mean_val = df[col].mean()
                std_val = df[col].std()
                lower_bound = mean_val - 3 * std_val
                upper_bound = mean_val + 3 * std_val
            else:  # IQRï¼ˆé»˜è®¤ï¼‰
                Q1 = df[col].quantile(0.25)
                Q3 = df[col].quantile(0.75)
                IQR = Q3 - Q1
                lower_bound = Q1 - 1.5 * IQR
                upper_bound = Q3 + 1.5 * IQR
            
            # ç­›é€‰å¼‚å¸¸å€¼
            outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]
            outlier_count = len(outliers)
            outlier_rate = (outlier_count / len(df) * 100).round(2)
            logger.info(f"åˆ—[{col}]ï¼šå¼‚å¸¸å€¼æ•°é‡={outlier_count} | å æ¯”={outlier_rate}% | åˆ¤å®šèŒƒå›´=[{lower_bound:.2f}, {upper_bound:.2f}]")
            
            # å¼‚å¸¸å€¼å¤„ç†ï¼šå æ¯”â‰¤é˜ˆå€¼åˆ™åˆ é™¤ï¼Œè¶…è¿‡åˆ™ä»…æç¤º
            if outlier_rate > 0:
                if outlier_rate <= outlier_threshold:
                    df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]
                    logger.info(f"åˆ—[{col}]ï¼šå·²åˆ é™¤å¼‚å¸¸è¡Œï¼Œå½“å‰è¡Œæ•°ï¼š{len(df)}")
                else:
                    logger.warning(f"åˆ—[{col}]ï¼šå¼‚å¸¸å€¼å æ¯”è¶…è¿‡é˜ˆå€¼ï¼ˆ{outlier_threshold}%ï¼‰ï¼Œè¯·æ’æŸ¥æ•°æ®é‡‡é›†é—®é¢˜ï¼Œæš‚ä¸å¤„ç†")

        # -------------------- æ­¥éª¤6ï¼šæ ¼å¼æ ‡å‡†åŒ– --------------------
        logger.info("\nã€æ­¥éª¤6ï¼šæ ¼å¼æ ‡å‡†åŒ–ã€‘")
        # å­—ç¬¦ä¸²åˆ—ï¼šå»ç©ºæ ¼ã€ç»Ÿä¸€å¤§å†™
        str_cols = df.select_dtypes(include=['object']).columns
        for col in str_cols:
            df[col] = df[col].astype(str).str.strip().str.upper()
            logger.info(f"åˆ—[{col}]ï¼šå®Œæˆå­—ç¬¦ä¸²æ ‡å‡†åŒ–ï¼ˆå»ç©ºæ ¼+å¤§å†™ï¼‰")
        
        # æ—¶é—´åˆ—ï¼šè‡ªåŠ¨è¯†åˆ«å¹¶æ ‡å‡†åŒ–
        time_cols = [col for col in df.columns if any(key in col.lower() for key in ['time', 'date', 'dt'])]
        for col in time_cols:
            df[col] = pd.to_datetime(df[col], errors='coerce')
            logger.info(f"åˆ—[{col}]ï¼šæ ‡å‡†åŒ–ä¸ºdatetimeæ ¼å¼")

        # -------------------- æ­¥éª¤7ï¼šæ•°æ®ä¿å­˜ --------------------
        logger.info("\nã€æ­¥éª¤7ï¼šæ•°æ®ä¿å­˜ã€‘")
        # æ–°å¢ï¼šæ£€æŸ¥è¾“å‡ºç›®å½•æ˜¯å¦å­˜åœ¨ï¼Œä¸å­˜åœ¨åˆ™åˆ›å»º
        output_dir = os.path.dirname(output_path)
        if output_dir and not os.path.exists(output_dir):
            os.makedirs(output_dir)
            logger.info(f"è¾“å‡ºç›®å½•ä¸å­˜åœ¨ï¼Œå·²åˆ›å»ºï¼š{output_dir}")
        
        df.to_csv(output_path, index=False, encoding='utf-8')
        final_shape = df.shape
        logger.info(f"æ¸…æ´—å®Œæˆï¼è¾“å‡ºæ–‡ä»¶ï¼š{output_path}")
        logger.info(f"æœ€ç»ˆæ•°æ®ç»´åº¦ï¼š{final_shape[0]}è¡Œ Ã— {final_shape[1]}åˆ—")
        logger.info(f"æ•°æ®æ¸…æ´—æ€»è§ˆï¼šåˆ é™¤é‡å¤è¡Œ{original_shape[0]-df.shape[0]}è¡Œ | ä¿ç•™åˆ—{final_shape[1]}åˆ—")
        logger.info("="*50)

        return df, log_file

    except Exception as e:
        # æ–°å¢ï¼šè¯¦ç»†è®°å½•å¼‚å¸¸æ ˆï¼Œä¾¿äºæ’æŸ¥
        logger.error(f"æ¸…æ´—è¿‡ç¨‹å‡ºé”™ï¼š{str(e)}", exc_info=True)
        logger.error(f"å¼‚å¸¸è¯¦ç»†æ ˆä¿¡æ¯ï¼š\n{traceback.format_exc()}")
        return None, log_file

# ===================== 3. å‘½ä»¤è¡Œå‚æ•°é…ç½®ï¼ˆæ–°å¢æ ¸å¿ƒï¼‰ =====================
def parse_args():
    """é…ç½®å‘½ä»¤è¡Œå‚æ•°ï¼Œæ”¯æŒç»ˆç«¯ç›´æ¥è¿è¡Œ"""
    parser = argparse.ArgumentParser(description="é€šç”¨CSVæ•°æ®æ¸…æ´—è„šæœ¬ V2.0ï¼ˆæ”¯æŒå‘½ä»¤è¡Œå‚æ•°+å¼ºåŒ–å¼‚å¸¸å¤„ç†ï¼‰")
    
    # å¿…é€‰å‚æ•°
    parser.add_argument('-i', '--input', required=True, help="è¾“å…¥CSVæ–‡ä»¶è·¯å¾„ï¼ˆå¿…å¡«ï¼‰ï¼Œç¤ºä¾‹ï¼š./åŸå§‹æ•°æ®.csv")
    parser.add_argument('-o', '--output', required=True, help="è¾“å‡ºæ¸…æ´—åCSVæ–‡ä»¶è·¯å¾„ï¼ˆå¿…å¡«ï¼‰ï¼Œç¤ºä¾‹ï¼š./æ¸…æ´—åæ•°æ®.csv")
    
    # å¯é€‰å‚æ•°ï¼ˆå‡æœ‰é»˜è®¤å€¼ï¼‰
    parser.add_argument('-l', '--log', default="æ¸…æ´—æ—¥å¿—", help="æ—¥å¿—æ–‡ä»¶åŸºç¡€è·¯å¾„ï¼Œé»˜è®¤ï¼šæ¸…æ´—æ—¥å¿—")
    parser.add_argument('-dt', '--duplicate_threshold', type=float, default=5.0, help="é‡å¤è¡Œå æ¯”é˜ˆå€¼ï¼ˆ%ï¼‰ï¼Œé»˜è®¤ï¼š5.0")
    parser.add_argument('-mfs', '--missing_fill_strategy', choices=['auto', 'mean', 'median', 'mode', 'drop'], 
                        default='auto', help="ç¼ºå¤±å€¼å¡«å……ç­–ç•¥ï¼Œå¯é€‰ï¼šauto/mean/median/mode/dropï¼Œé»˜è®¤ï¼šauto")
    parser.add_argument('-mct', '--missing_col_threshold', type=float, default=30.0, help="åˆ—ç¼ºå¤±ç‡é˜ˆå€¼ï¼ˆ%ï¼‰ï¼Œé»˜è®¤ï¼š30.0")
    parser.add_argument('-om', '--outlier_method', choices=['IQR', '3Ïƒ'], default='IQR', help="å¼‚å¸¸å€¼åˆ¤å®šæ–¹æ³•ï¼Œå¯é€‰ï¼šIQR/3Ïƒï¼Œé»˜è®¤ï¼šIQR")
    parser.add_argument('-ot', '--outlier_threshold', type=float, default=5.0, help="å¼‚å¸¸å€¼å æ¯”é˜ˆå€¼ï¼ˆ%ï¼‰ï¼Œé»˜è®¤ï¼š5.0")
    
    return parser.parse_args()

# ===================== 4. æµ‹è¯•æ•°æ®ç”Ÿæˆï¼ˆä¿ç•™ï¼‰ =====================
def generate_test_student_data(test_path="å­¦ç”Ÿæˆç»©_åŸå§‹æ•°æ®.csv"):
    """ç”Ÿæˆæ¨¡æ‹Ÿçš„å­¦ç”Ÿæˆç»©æµ‹è¯•æ•°æ®ï¼ˆåŒ…å«é‡å¤ã€ç¼ºå¤±ã€å¼‚å¸¸ã€æ ¼å¼é—®é¢˜ï¼‰"""
    data = {
        "å­¦å·": ["2024001", "2024002", "2024003", "2024004", "2024005", "2024002", "2024006", "2024007", "2024008", "2024009", "2024010"],
        "å§“å": [" å¼ ä¸‰ ", "æå››", "ç‹äº”", "èµµå…­", "é’±ä¸ƒ", "æå››", "å­™å…«", "å‘¨ä¹", "å´å", "éƒ‘åä¸€", "å†¯åäºŒ"],
        "è¯­æ–‡": [85, 92, np.nan, 78, 88, 92, 95, 80, 75, 89, 82],
        "æ•°å­¦": [90, np.nan, 85, np.nan, 78, np.nan, 200, np.nan, 88, np.nan, 95],
        "è‹±è¯­": [78, 85, 90, 82, 88, 85, 92, 75, 80, 89, np.nan],
        "è€ƒè¯•æ—¥æœŸ": ["2024-06-20", "2024/06/20", "2024.06.20", "2024-06-20", "2024-06-20", "2024/06/20", "2024-06-20", "2024-06-20", "2024-06-20", "2024-06-20", "2024-06-20"],
        "ç­çº§": [" ä¸€ç­ ", "äºŒç­", "ä¸‰ç­", "ä¸€ç­", "äºŒç­", "äºŒç­", "ä¸‰ç­", "ä¸€ç­", "äºŒç­", "ä¸‰ç­", "ä¸€ç­"]
    }
    df = pd.DataFrame(data)
    df.to_csv(test_path, index=False, encoding='utf-8')
    print(f"æµ‹è¯•æ•°æ®å·²ç”Ÿæˆï¼š{test_path}")
    return test_path

# ===================== 5. ä¸»å‡½æ•°ï¼ˆæ•´åˆå‘½ä»¤è¡Œ+æ¸…æ´—é€»è¾‘ï¼‰ =====================
def main():
    """ä¸»å‡½æ•°ï¼šè§£æå‘½ä»¤è¡Œå‚æ•° â†’ æ‰§è¡Œæ¸…æ´— â†’ è¾“å‡ºç»“æœ"""
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    args = parse_args()
    
    # æ‰§è¡Œæ¸…æ´—
    print("="*60)
    print("å¼€å§‹æ‰§è¡Œé€šç”¨CSVæ•°æ®æ¸…æ´—è„šæœ¬ V2.0")
    print(f"è¾“å…¥æ–‡ä»¶ï¼š{args.input}")
    print(f"è¾“å‡ºæ–‡ä»¶ï¼š{args.output}")
    print("="*60)
    
    cleaned_df, log_file = clean_csv_data(
        input_path=args.input,
        output_path=args.output,
        log_path=args.log,
        duplicate_threshold=args.duplicate_threshold,
        missing_fill_strategy=args.missing_fill_strategy,
        missing_col_threshold=args.missing_col_threshold,
        outlier_method=args.outlier_method,
        outlier_threshold=args.outlier_threshold
    )
    
    # è¾“å‡ºæœ€ç»ˆç»“æœ
    if cleaned_df is not None:
        print(f"\nâœ… æ¸…æ´—æˆåŠŸï¼")
        print(f"ğŸ“„ æ¸…æ´—åæ•°æ®é¢„è§ˆï¼š\n{cleaned_df.head()}")
        print(f"ğŸ“ æ—¥å¿—æ–‡ä»¶è·¯å¾„ï¼š{log_file}")
    else:
        print(f"\nâŒ æ¸…æ´—å¤±è´¥ï¼")
        print(f"ğŸ“ é”™è¯¯æ—¥å¿—å·²ä¿å­˜è‡³ï¼š{log_file}ï¼Œè¯·æŸ¥çœ‹æ—¥å¿—æ’æŸ¥é—®é¢˜")

# ===================== 6. å…¥å£å‡½æ•°ï¼ˆæ”¯æŒå‘½ä»¤è¡Œ+è„šæœ¬è¿è¡Œï¼‰ =====================
if __name__ == "__main__":
    # æ–¹å¼1ï¼šå‘½ä»¤è¡Œè¿è¡Œï¼ˆä¼˜å…ˆï¼‰
    try:
        main()
    # æ–¹å¼2ï¼šè„šæœ¬ç›´æ¥è¿è¡Œï¼ˆæµ‹è¯•ç”¨ï¼Œä¿ç•™åŸæµ‹è¯•é€»è¾‘ï¼‰
    except SystemExit:
        # è‹¥æœªä¼ å…¥å‘½ä»¤è¡Œå‚æ•°ï¼Œè‡ªåŠ¨ç”Ÿæˆæµ‹è¯•æ•°æ®å¹¶è¿è¡Œ
        print("\nâš ï¸  æœªä¼ å…¥å‘½ä»¤è¡Œå‚æ•°ï¼Œè‡ªåŠ¨æ‰§è¡Œæµ‹è¯•æ¨¡å¼...")
        # 1. ç”Ÿæˆæµ‹è¯•æ•°æ®
        test_input = generate_test_student_data()
        # 2. é…ç½®æ¸…æ´—å‚æ•°ï¼ˆè°ƒé«˜é‡å¤è¡Œé˜ˆå€¼ï¼Œé¿å…ç»ˆæ­¢ï¼‰
        test_output = "å­¦ç”Ÿæˆç»©_æ¸…æ´—åæ•°æ®.csv"
        # 3. æ‰§è¡Œæ¸…æ´—
        cleaned_df, log_file = clean_csv_data(
            input_path=test_input,
            output_path=test_output,
            duplicate_threshold=10.0,  # è°ƒé«˜é˜ˆå€¼ï¼Œé€‚é…æµ‹è¯•æ•°æ®çš„9.09%é‡å¤ç‡
            missing_fill_strategy="auto",
            missing_col_threshold=30.0,
            outlier_method="IQR",
            outlier_threshold=5.0
        )
        # è¾“å‡ºæµ‹è¯•ç»“æœ
        if cleaned_df is not None:
            print(f"\nâœ… æµ‹è¯•æ¨¡å¼ - æ¸…æ´—æˆåŠŸï¼")
            print(f"ğŸ“„ æ¸…æ´—åæ•°æ®é¢„è§ˆï¼š\n{cleaned_df.head()}")
            print(f"ğŸ“ æ—¥å¿—æ–‡ä»¶è·¯å¾„ï¼š{log_file}")
        else:
            print(f"\nâŒ æµ‹è¯•æ¨¡å¼ - æ¸…æ´—å¤±è´¥ï¼")
            print(f"ğŸ“ é”™è¯¯æ—¥å¿—å·²ä¿å­˜è‡³ï¼š{log_file}")
    except Exception as e:
        print(f"\nâŒ è„šæœ¬è¿è¡Œå‡ºé”™ï¼š{str(e)}")
        print(f"ğŸ“ å¼‚å¸¸è¯¦æƒ…ï¼š\n{traceback.format_exc()}")
```

### 3. æ ¸å¿ƒä¼˜åŒ–ç‚¹è¯¦è§£
#### ï¼ˆ1ï¼‰å¼ºåŒ–å¼‚å¸¸å¤„ç†ï¼ˆè¦†ç›–å…³é”®åœºæ™¯ï¼‰
| å¼‚å¸¸åœºæ™¯                | å¤„ç†æ–¹å¼                                                                 | ä¼˜åŒ–æ•ˆæœ                                                                 |
|-------------------------|--------------------------------------------------------------------------|--------------------------------------------------------------------------|
| æ–‡ä»¶ä¸å­˜åœ¨              | æ•è·`FileNotFoundError`ï¼Œæ—¥å¿—è®°å½•å¹¶å‹å¥½æç¤º                             | é¿å…è„šæœ¬å´©æºƒï¼Œæ˜ç¡®å‘ŠçŸ¥æ–‡ä»¶è·¯å¾„é”™è¯¯                                       |
| æ ¼å¼é”™è¯¯ï¼ˆä¼ å…¥Excelï¼‰| å‰ç½®æ ¡éªŒ`input_path`æ˜¯å¦ä»¥`.csv`ç»“å°¾ï¼ŒæŠ›å‡º`ValueError`å¹¶è®°å½•            | æå‰æ‹¦æˆªéCSVæ–‡ä»¶ï¼Œé¿å…`pd.read_csv`è¯»å–å¤±è´¥çš„æ¨¡ç³Šé”™è¯¯                   |
| è¾“å‡ºè·¯å¾„ç›®å½•ä¸å­˜åœ¨      | è‡ªåŠ¨åˆ›å»ºè¾“å‡ºç›®å½•ï¼ˆ`os.makedirs`ï¼‰                                       | é¿å…å› ç›®å½•ä¸å­˜åœ¨å¯¼è‡´ä¿å­˜å¤±è´¥                                             |
| ç©ºæ•°æ®                  | æ£€æµ‹`df.empty`ï¼ŒæŠ›å‡º`ValueError`                                         | é¿å…åç»­æ¸…æ´—é€»è¾‘å¤„ç†ç©ºæ•°æ®                                             |
| é€šç”¨è¿è¡Œæ—¶å¼‚å¸¸          | æ•è·æ‰€æœ‰`Exception`ï¼Œè®°å½•å®Œæ•´å¼‚å¸¸æ ˆï¼ˆ`traceback.format_exc()`ï¼‰         | ä¾¿äºå®šä½å…·ä½“é”™è¯¯è¡Œï¼Œå¿«é€Ÿæ’æŸ¥é—®é¢˜                                         |
| æ—¥å¿—é‡å¤æ‰“å°            | æ¸…ç©ºæ—¥å¿—å™¨å·²æœ‰å¤„ç†å™¨ï¼ˆ`logger.handlers.clear()`ï¼‰                       | ä¿®å¤åŸè„šæœ¬ä¸­æè¿°æ€§ç»Ÿè®¡é‡å¤æ‰“å°çš„é—®é¢˜                                     |

#### ï¼ˆ2ï¼‰å‘½ä»¤è¡Œå‚æ•°æ”¯æŒï¼ˆargparseï¼‰
è„šæœ¬æ–°å¢`parse_args()`å‡½æ•°ï¼Œæ”¯æŒç»ˆç«¯ç›´æ¥è¿è¡Œï¼Œæ ¸å¿ƒå‚æ•°è¯´æ˜ï¼š
```bash
# ç»ˆç«¯è¿è¡Œç¤ºä¾‹ï¼ˆåŸºç¡€ç”¨æ³•ï¼‰
python æ¸…æ´—è„šæœ¬V2.0.py -i å­¦ç”Ÿæˆç»©_åŸå§‹æ•°æ®.csv -o å­¦ç”Ÿæˆç»©_æ¸…æ´—å.csv

# å®Œæ•´å‚æ•°ç¤ºä¾‹ï¼ˆè‡ªå®šä¹‰é˜ˆå€¼ï¼‰
python æ¸…æ´—è„šæœ¬V2.0.py \
  -i ./data/åŸå§‹æ•°æ®.csv \
  -o ./data/æ¸…æ´—åæ•°æ®.csv \
  -l ./logs/å­¦ç”Ÿæˆç»© \
  -dt 10.0 \
  -mfs median \
  -mct 20.0 \
  -om 3Ïƒ \
  -ot 2.0
```
å‚æ•°è¯´æ˜ï¼š
| å‚æ•°                | ç®€å†™ | ä½œç”¨                                  | é»˜è®¤å€¼  |
|---------------------|------|---------------------------------------|---------|
| `--input`           | `-i` | è¾“å…¥CSVè·¯å¾„ï¼ˆå¿…å¡«ï¼‰                   | æ—       |
| `--output`          | `-o` | è¾“å‡ºCSVè·¯å¾„ï¼ˆå¿…å¡«ï¼‰                   | æ—       |
| `--log`             | `-l` | æ—¥å¿—åŸºç¡€è·¯å¾„                          | æ¸…æ´—æ—¥å¿— |
| `--duplicate_threshold` | `-dt` | é‡å¤è¡Œå æ¯”é˜ˆå€¼ï¼ˆ%ï¼‰ | 5.0     |
| `--missing_fill_strategy` | `-mfs` | ç¼ºå¤±å€¼å¡«å……ç­–ç•¥ | auto    |
| `--missing_col_threshold` | `-mct` | åˆ—ç¼ºå¤±ç‡é˜ˆå€¼ï¼ˆ%ï¼‰ | 30.0    |
| `--outlier_method`  | `-om` | å¼‚å¸¸å€¼åˆ¤å®šæ–¹æ³•ï¼ˆIQR/3Ïƒï¼‰              | IQR     |
| `--outlier_threshold` | `-ot` | å¼‚å¸¸å€¼å æ¯”é˜ˆå€¼ï¼ˆ%ï¼‰ | 5.0     |

#### ï¼ˆ3ï¼‰é€‚é…æµ‹è¯•æ¨¡å¼
è„šæœ¬å…¥å£å‡½æ•°åšäº†å…¼å®¹ï¼š
- è‹¥ä¼ å…¥å‘½ä»¤è¡Œå‚æ•° â†’ æŒ‰å‘½ä»¤è¡Œæ¨¡å¼è¿è¡Œï¼›
- è‹¥æœªä¼ å‚æ•° â†’ è‡ªåŠ¨ç”Ÿæˆæµ‹è¯•æ•°æ®ï¼Œå¹¶**è°ƒé«˜é‡å¤è¡Œé˜ˆå€¼è‡³10.0%**ï¼ˆé€‚é…æµ‹è¯•æ•°æ®çš„9.09%é‡å¤ç‡ï¼‰ï¼Œé¿å…æµ‹è¯•ç»ˆæ­¢ã€‚

### 4. å¼‚å¸¸åœºæ™¯æµ‹è¯•ï¼ˆéªŒè¯ä¼˜åŒ–æ•ˆæœï¼‰
#### åœºæ™¯1ï¼šä¼ å…¥Excelæ–‡ä»¶ï¼ˆæ ¼å¼é”™è¯¯ï¼‰
```bash
# 1. å…ˆç”Ÿæˆä¸€ä¸ªExcelæµ‹è¯•æ–‡ä»¶ï¼ˆæ¨¡æ‹Ÿé”™è¯¯è¾“å…¥ï¼‰
python -c "import pandas as pd; pd.DataFrame({'a':[1,2]}).to_excel('é”™è¯¯æ•°æ®.xlsx', index=False)"

# 2. ç”¨è„šæœ¬æ¸…æ´—è¯¥Excelæ–‡ä»¶
python æ¸…æ´—è„šæœ¬V2.0.py -i é”™è¯¯æ•°æ®.xlsx -o æ¸…æ´—å.csv
```
**é¢„æœŸç»“æœ**ï¼š
- æ§åˆ¶å°æç¤º`âŒ æ¸…æ´—å¤±è´¥ï¼`ï¼›
- æ—¥å¿—ä¸­è®°å½•`è¾“å…¥æ–‡ä»¶æ ¼å¼é”™è¯¯ï¼ä»…æ”¯æŒCSVæ–‡ä»¶ï¼Œå½“å‰æ–‡ä»¶ï¼šé”™è¯¯æ•°æ®.xlsx`ï¼›
- æ— å´©æºƒï¼Œé”™è¯¯ä¿¡æ¯æ¸…æ™°ã€‚

#### åœºæ™¯2ï¼šè¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨
```bash
python æ¸…æ´—è„šæœ¬V2.0.py -i ä¸å­˜åœ¨çš„æ–‡ä»¶.csv -o æ¸…æ´—å.csv
```
**é¢„æœŸç»“æœ**ï¼š
- æ§åˆ¶å°æç¤º`âŒ æ¸…æ´—å¤±è´¥ï¼`ï¼›
- æ—¥å¿—ä¸­è®°å½•`è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨ï¼šä¸å­˜åœ¨çš„æ–‡ä»¶.csv`ï¼›
- å®Œæ•´å¼‚å¸¸æ ˆè®°å½•ï¼Œä¾¿äºæ’æŸ¥ã€‚

#### åœºæ™¯3ï¼šé‡å¤è¡Œå æ¯”è¶…é˜ˆå€¼
```bash
# ç”¨é»˜è®¤é˜ˆå€¼5.0%æ¸…æ´—æµ‹è¯•æ•°æ®ï¼ˆé‡å¤ç‡9.09%ï¼‰
python æ¸…æ´—è„šæœ¬V2.0.py -i å­¦ç”Ÿæˆç»©_åŸå§‹æ•°æ®.csv -o æ¸…æ´—å.csv -dt 5.0
```
**é¢„æœŸç»“æœ**ï¼š
- æ§åˆ¶å°æç¤º`âŒ æ¸…æ´—å¤±è´¥ï¼`ï¼›
- æ—¥å¿—ä¸­è®°å½•`é‡å¤è¡Œå æ¯”ï¼ˆ9.09%ï¼‰è¶…è¿‡é˜ˆå€¼ï¼ˆ5.0%ï¼‰ï¼Œç»ˆæ­¢æ¸…æ´—`ï¼›
- é”™è¯¯åŸå› æ˜ç¡®ï¼Œå¯é€šè¿‡è°ƒé«˜`-dt`å‚æ•°è§£å†³ã€‚

#### åœºæ™¯4ï¼šè¾“å‡ºç›®å½•ä¸å­˜åœ¨
```bash
# è¾“å‡ºè·¯å¾„æŒ‡å®šä¸å­˜åœ¨çš„ç›®å½•
python æ¸…æ´—è„šæœ¬V2.0.py -i å­¦ç”Ÿæˆç»©_åŸå§‹æ•°æ®.csv -o ./ä¸å­˜åœ¨çš„ç›®å½•/æ¸…æ´—å.csv -dt 10.0
```
**é¢„æœŸç»“æœ**ï¼š
- è„šæœ¬è‡ªåŠ¨åˆ›å»º`ä¸å­˜åœ¨çš„ç›®å½•`ï¼›
- æ¸…æ´—æˆåŠŸï¼Œæ•°æ®ä¿å­˜è‡³è¯¥ç›®å½•ï¼›
- æ—¥å¿—ä¸­è®°å½•`è¾“å‡ºç›®å½•ä¸å­˜åœ¨ï¼Œå·²åˆ›å»ºï¼š./ä¸å­˜åœ¨çš„ç›®å½•`ã€‚

### 5. æ€»ç»“
1. **æ ¸å¿ƒåŠŸèƒ½**ï¼šä¿ç•™åŸæ¸…æ´—æµç¨‹çš„æ‰€æœ‰æ ¸å¿ƒé€»è¾‘ï¼Œå¼ºåŒ–äº†å¼‚å¸¸å¤„ç†çš„è¦†ç›–èŒƒå›´å’Œå‹å¥½æ€§ï¼›
2. **å‘½ä»¤è¡Œæ”¯æŒ**ï¼šæ–°å¢`argparse`ï¼Œå¯é€šè¿‡ç»ˆç«¯çµæ´»é…ç½®å‚æ•°ï¼Œé€‚é…ç”Ÿäº§ç¯å¢ƒè¿è¡Œï¼›
3. **å¼‚å¸¸æµ‹è¯•**ï¼šè¦†ç›–æ ¼å¼é”™è¯¯ã€æ–‡ä»¶ä¸å­˜åœ¨ã€ç›®å½•ä¸å­˜åœ¨ã€é‡å¤è¡Œè¶…é˜ˆå€¼ç­‰åœºæ™¯ï¼Œé”™è¯¯ä¿¡æ¯æ¸…æ™°ã€æ—¥å¿—å¯è¿½æº¯ï¼›
4. **å…¼å®¹æ€§**ï¼šåŒæ—¶æ”¯æŒå‘½ä»¤è¡Œè¿è¡Œï¼ˆç”Ÿäº§ï¼‰å’Œè„šæœ¬ç›´æ¥è¿è¡Œï¼ˆæµ‹è¯•ï¼‰ï¼Œå…¼é¡¾ä¸åŒä½¿ç”¨åœºæ™¯ã€‚

å…³é”®ä¼˜åŒ–è®°å¿†ç‚¹ï¼š
- å¼‚å¸¸å¤„ç†ï¼šå‰ç½®æ ¡éªŒ+å®Œæ•´æ ˆè®°å½•ï¼Œé¿å…å´©æºƒä¸”æ˜“æ’æŸ¥ï¼›
- å‘½ä»¤è¡Œï¼š`-i/-o`å¿…å¡«ï¼Œå…¶ä»–å‚æ•°å¯é€‰ï¼Œç»ˆç«¯è¿è¡Œæ›´çµæ´»ï¼›
- æµ‹è¯•å…¼å®¹ï¼šæœªä¼ å‚æ•°è‡ªåŠ¨æ‰§è¡Œæµ‹è¯•æ¨¡å¼ï¼Œè°ƒé«˜é‡å¤è¡Œé˜ˆå€¼é¿å…ç»ˆæ­¢ã€‚